{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-insurance-linear.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54229ad4ddda43189a5283a0e9d93691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0013d9da8e74bef911ce48f17662142",
              "IPY_MODEL_6b7bfba12b754f0692a20010e5f14e9f"
            ],
            "layout": "IPY_MODEL_20d33b3296d04346b94993ea9cbd88c2"
          }
        },
        "20d33b3296d04346b94993ea9cbd88c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0013d9da8e74bef911ce48f17662142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197fd2664dba46baa19930c5cded2882",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_326caa6d79cf4d61a180c2c5357438b1",
            "value": 1
          }
        },
        "6b7bfba12b754f0692a20010e5f14e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eae6a6d67212467b98668fdd2ea82832",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_404e93c41ecc4aa89f0a0f3d67a2e48b",
            "value": " 57344/? [00:20&lt;00:00, 129719.60it/s]"
          }
        },
        "326caa6d79cf4d61a180c2c5357438b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "197fd2664dba46baa19930c5cded2882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404e93c41ecc4aa89f0a0f3d67a2e48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eae6a6d67212467b98668fdd2ea82832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz29qfLUgPxf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "mczXlTYazAly"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n",
        "\n",
        "Make a submisson here: https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-2-train-your-first-model\n",
        "\n",
        "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from [Kaggle](https://www.kaggle.com/mirichoi0218/insurance).\n",
        "\n",
        "\n",
        "We will create a model with the following steps:\n",
        "1. Download and explore the dataset\n",
        "2. Prepare the dataset for training\n",
        "3. Create a linear regression model\n",
        "4. Train the model to fit the data\n",
        "5. Make predictions using the trained model\n",
        "\n",
        "\n",
        "This assignment builds upon the concepts from the first 2 lessons. It will help to review these Jupyter notebooks:\n",
        "- PyTorch basics: https://jovian.ai/aakashns/01-pytorch-basics\n",
        "- Linear Regression: https://jovian.ai/aakashns/02-linear-regression\n",
        "- Logistic Regression: https://jovian.ai/aakashns/03-logistic-regression\n",
        "- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2UwQ0vVzAl1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FvTySijzAl3"
      },
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-lMjBR9zAl4"
      },
      "source": [
        "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJV2pRy8zAl4"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "54229ad4ddda43189a5283a0e9d93691",
            "20d33b3296d04346b94993ea9cbd88c2",
            "b0013d9da8e74bef911ce48f17662142",
            "6b7bfba12b754f0692a20010e5f14e9f",
            "326caa6d79cf4d61a180c2c5357438b1",
            "197fd2664dba46baa19930c5cded2882",
            "404e93c41ecc4aa89f0a0f3d67a2e48b",
            "eae6a6d67212467b98668fdd2ea82832"
          ]
        },
        "id": "PgvWZnnJzAl8",
        "outputId": "e20c7c5e-1598-4ceb-e365-eb9dbedbeeb7"
      },
      "source": [
        "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54229ad4ddda43189a5283a0e9d93691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MXnbqVWzAl-"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jCkepXdOzAl-",
        "outputId": "15332381-2908-43f5-c903-e5d31d496644"
      },
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0-0uIMzAl_"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnlMMixQzAl_"
      },
      "source": [
        "your_name = 'lawrence' # at least 5 characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FjEhyc5zAmC"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wl75PctzAmD"
      },
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4e8HJJP8zAmD",
        "outputId": "605e5bb7-5510-4cdf-9962-5512f7d778c1"
      },
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>23.36730</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>2619.305549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>36.49140</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>southeast</td>\n",
              "      <td>44226.544922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>45</td>\n",
              "      <td>male</td>\n",
              "      <td>29.58015</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10012.021030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>62</td>\n",
              "      <td>female</td>\n",
              "      <td>38.02400</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16030.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>60</td>\n",
              "      <td>female</td>\n",
              "      <td>23.79410</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>15029.577073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age     sex       bmi  children smoker     region       charges\n",
              "469   18  female  23.36730         1     no  southeast   2619.305549\n",
              "82    22    male  36.49140         1    yes  southeast  44226.544922\n",
              "517   45    male  29.58015         2     no  northwest  10012.021030\n",
              "499   62  female  38.02400         0     no  southwest  16030.323400\n",
              "48    60  female  23.79410         0     no  southeast  15029.577073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX5kzXpLzAmD"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDJeTHBFzAmE",
        "outputId": "60f4dac7-389a-4f8e-9e13-266bc97f32a5"
      },
      "source": [
        "num_rows = len(dataframe.index)\n",
        "print(num_rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wPqKIzxzAmE"
      },
      "source": [
        "**Q: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lsERvLRzAmF",
        "outputId": "beee283b-275a-47ef-c380-e078a2cbf71a"
      },
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCo4C4Z4zAmG"
      },
      "source": [
        "**Q: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCXJBixxzAmG",
        "outputId": "7ecf8ff3-e02c-49b6-ec95-75c75c58fc45"
      },
      "source": [
        "input_cols = [i for i in dataframe.columns[:-1]]\n",
        "#list from age to region\n",
        "input_cols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'sex', 'bmi', 'children', 'smoker', 'region']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKKDS1zGzAmH"
      },
      "source": [
        "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUMguvLfzAmH",
        "outputId": "786b7795-1e62-405c-c19e-97f092e0f4be"
      },
      "source": [
        "categorical_cols = [i for i in dataframe.select_dtypes(exclude=['number']).columns]\n",
        "categorical_cols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sex', 'smoker', 'region']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR1kqqqMzAmH"
      },
      "source": [
        "**Q: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlXN3X6fzAmI",
        "outputId": "d4bca723-1a68-4edb-f4bf-e4bcb6f480c5"
      },
      "source": [
        "output_cols = [dataframe.columns[-1]]\n",
        "output_cols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['charges']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAU5VSZnzAmI"
      },
      "source": [
        "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
        "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtCRqHZhzAmJ",
        "outputId": "74cef2b0-3f3c-410e-ca31-b0d569147e01"
      },
      "source": [
        "print(\"Minimum value : {} \".format(dataframe['charges'].min()))\n",
        "print(\"Maximum value : {} \".format(dataframe['charges'].max()))\n",
        "print(\"Average value :: {} \".format(dataframe['charges'].mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum value : 1335.029941 \n",
            "Maximum value : 75886.8093319 \n",
            "Average value :: 15828.656992017379 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "0rl3PAasFPil",
        "outputId": "12f7e1c0-9a10-43d6-85fb-267b8f871e60"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.hist(dataframe.charges)\n",
        "plt.grid()\n",
        "plt.xlabel(\"Charges\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "xpQc_8hLGReF",
        "outputId": "9de6a09e-805b-4668-c280-dc0bba04066b"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.distplot(dataframe.charges, kde=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAERCAYAAAAKQn74AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXQUVb4H8G/1mu50kk6HTmeFEBIIawBFQB2QbIR9F0dHfAzznDdPAQ+DC+PDZdRZnNEz45tx1Deu4zIuIDgoOApEFkHQBJCEPZCNpBOS7k7Se1ff90eTmJA9dPX6+5zDOVLV1fWrlPlSt+6tWxxjjIEQQsKQyN8FEEKIv1AAEkLCFgUgISRsUQASQsIWBSAhJGxRABJCwpbE3wVca9OmTSgqKkJcXBx27Nhx3d83evRojBw5EgCQmJiIl1566bq/kxASGrhAGwd49OhRKJVKPPzww14JwEmTJqGkpMQLlRFCQk3ANYGnTJmCmJiYTssqKyuxZs0aLF26FHfeeScuXLjgp+oIIaEk4JrA3dm8eTOefPJJpKWl4fjx43jyySfx1ltv9Wtbu92OpUuXQiKR4N5770VeXp7A1RJCgkXAB6DZbEZJSQnWr1/fvszhcAAA/v3vf+OFF17oso1Op8Orr74KANi7dy90Oh2qqqpwzz33YOTIkRg6dKhviieEBLSAD0DGGKKjo7F9+/Yu6woKClBQUNDr9jqdDgCQmpqKm266CWVlZRSAhBAAAXgP8FoqlQopKSnYuXMnAE8gnj59ul/bmkym9qvFpqYmFBcXIyMjQ7BaCSHBJeB6gTds2IAjR47AYDAgLi4Oa9euxbRp0/DEE0+goaEBLpcLc+fOxf3339/ndxUXF+Pxxx8Hx3FgjGHVqlVYsWKFD46CEBIMAi4ACSHEVwK+CUwIIUIJqE4Qt9sNng+cC1KxmAuoerwlFI+Ljik4+OuYpFJxt8sDKgB5nsFotPi7jHZqtTKg6vGWUDwuOqbg4K9j0mqjul1OTWBCSNiiACSEhC0KQEJI2KIAJISELQpAQkjYogAkhIQtCkBCSNiiACSEhC0KQEJI2AqoJ0ECnZ0BFiff7TqlVAw55+OCCCHXhQJwACxOHntP13e7blZWPOSy7p83JIQEJmoCE0LClqAB2NzcjHXr1qGwsBBz5syh11MSQgKKoE3gZ555Bj/60Y/wwgsvwOFwwGazCbk7QggZEMGuAFtaWnD06FEsX74cACCTyRAdHS3U7gghZMAEuwKsrq6GRqPBpk2bcPr0aYwdOxaPPvoolEplj9uIxRzU6p7X+5pYLOpUj9Vkg1Ih6/azEXIp1DERvirtulx7XKGAjik4BNoxCRaALpcLZWVl2Lx5M7Kzs/H000/jlVdewQMPPNDjNoE+IarNwcNidXT7WZvdCaPR7avSrgtNtBkc6Ji8x+cToiYkJCAhIQHZ2dkAgMLCQpSVlQm1O0IIGTDBAlCr1SIhIQHl5eUAgEOHDmHEiBFC7Y4QQgZM0F7gzZs3Y+PGjXA6nUhNTcVvf/tbIXdHCCEDImgAjh49Glu3bhVyF4QQMmj0JAghJGxRABJCwhYFICEkbFEAEkLCFgUgISRsUQASQsIWBSAhJGxRABJCwhYFICEkbFEAEkLCFgUgISRsUQASQsIWBSAhJGxRABJCwhYFICEkbFEAEkLCFgUgISRsUQASQsIWBSAhJGwJ+k6QcMJxHAwOvtt1SqkYcs7HBRFC+kQB6CVWlxuHzjV0u25WVjzkMrGPKyKE9IWawISQsEUBSAgJWxSAhJCwJeg9wJycHERGRkIkEkEsFtNL0gkhAUXwTpA333wTGo1G6N0QQsiAUROYEBK2BL8CXLNmDTiOw8qVK7Fy5cpePysWc1CrlUKX1G9isahTPVaTDUqFrNvPSsSiHtdFyKVQx0QIUuNgXHtcoYCOKTgE2jEJGoDvvfcedDodGhsbsXr1aqSnp2PKlCk9fp7nGYxGi5AlDYharexUj83Bw2J1dPtZF+/ucZ3N7oTR6BakxsG49rhCAR1TcPDXMWm1Ud0uF7QJrNPpAABxcXHIz8/HiRMnhNwdIYQMiGABaLFY0Nra2v7fBw8eRGZmplC7I4SQAROsCdzY2Ij77rsPAMDzPObPn48ZM2YItTtCCBkwwQIwNTUVn3zyiVBfTwgh142GwRBCwhYFICEkbFEAEkLCFgUgISRsUQASQsIWBSAhJGxRABJCwhYFoI8wxvxdAiHkGvRSJAEZLA58db4Rz+4+D8YYbh6uwc+mDcXYxGh/l0YIAV0BCqbJ4sBbR6tx4YoZ88clYOWkZJTVtWDNP4/jg5LL/i6PEAK6AhSEk3fjg+LLYIzhP6YOxfIbUhArE+M/pw/D4ztP4w97zsPNGO6YnOzvUgkJa3QFKIAjFUYYrE4sHp+IuMgfJkmNipDg2UVjcVtGHJ7bewFfnW/0Y5WEEApAL2u1u3DoUhNGxUciLa7rzLcSEYen541GVrwKT+46gxqT1Q9VEkIACkCvK6k2wckzzMwY0uNn5BIRfrdwNNyM4enPz1IPMSF+QgHoRW43w/GaZgyPU3Zq+nIcB4OD7/RHqZDhvhnp+LbKhI+/r/Nj1YSEL+oE8aILjWa02F3Iz9J2Wm51uXHoXEOXz+dmabH7TD1e3H8RuZlDEKOQtq+zM8Di5Lvdj1Iqhpzzbu2EhCMKQC8qrW2BUipGxpDIfn2e4zj8ctYI/OQfxfi/QxXYmJPRvs7i5LH3dH23283KiodcJvZKzYSEM2oCe4mTd6O80YJMbSTEov5fnmVqVVg8PhEfHa9FtZE6RAjxJQpALzl5uRl2lxuZ8f27+uvoZ9OHQiLi8OrhSgEqI4T0hALQS7652ASJiEOapv8vfW7rHJHIJJg3LgGflelxsr4VBgcPnjqGCREc3QP0kuJKA9I0SkjF/f83pWPnSEq0HBzH4c97zmPOGB2mZ2r72JoQcr3oCtALmm1O1DXbMUyjGPR3RMolmJAYhe9rW2C2u7xYHSGkJxSAXlBp8HReDBtA87c7Nw2LBe9m+LbK5I2yCCF9oAD0gkqDFZFyMbQqWd8f7oUmUoaMIZE4XmOCk3d7qTpCSE8oAL2gssmKsYnREHHXPzp5cmoMzA4eh8ubvFAZIaQ3ggcgz/NYvHgxfv7znwu9K79otbtgsDq9NslpepwSaoUEn5XS43GECE3wAHzrrbcwYsQIoXfjN7UmGwBgVEKUV76P4zhkJ8eg9HIzDBaHV76TENI9QQOwrq4ORUVFWL58uZC78avLzXZwANL7+fhbf4xLjAIH4PvaFq99JyGkK0HHAf7mN7/Bgw8+CLPZ3K/Pi8Uc1Orr60n1JrFY1Kkeq8kGpaJzR0d9qwPxUXKoIqRd1rWRiEXdrutpuVIhw6ShapTWtqBgbEKXe4sRcinUMRGDOSQAXY8rFNAxBYdAOybBAnDv3r3QaDQYN24cvvnmm35tw/MMRqNFqJIGTK1WdqrH5uBhsf7QLGWModpowUitCi7e3WldRz2t622bWSO1KK404lxtM1JjO48vtNmdMBoH30t87XGFAjqm4OCvY9Jqu79FJVgAFhcXY8+ePdi3bx/sdjtaW1uxceNG/PGPfxRqlz5ntLpgc7qRGC33+nffNFwDiYhDmb6lSwASQrxDsHuAv/zlL7Fv3z7s2bMHzz//PKZNmxZS4QcAdc2eDpDE62iO9kRxdVqtM/pWuGnGaEIEQeMAr0N9qx0ch+seAN2T0QkqmB18+5MmhBDv8slkCFOnTsXUqVN9sSufqm9xIE4pg0QkzL8jI4ZEQiLicK7ePKBZZggh/UNXgNehvtWO+Chhrv4AQCoWYZhGgfNXWunFSYQIgAJwkGxOHs02F+JV3u8A6ShjSCSMVhcazU5B90NIOKIAHKSGVs/wFa3QAaj1DLA+f6V/YykJIf3XrwC8//77UVRUBLebZihpU99qBwBBm8AAEB0hRbxKhvMNFICEeFu/AvDOO+/Ev/71LxQUFOCPf/wjysvLha4r4NW32BEhESFKLnw/UoZWhWqTFdYeXpNJCBmcfgXgzTffjOeeew4ff/wxkpOTsXr1atxxxx3YsmULnM7wvDfVaHZiiEoGzgtTYPUlQxsJxoByagYT4lX9vgdoMBiwdetWfPjhhxg9ejRWrVqFsrIy/PSnPxWyvoDVaHFAoxS2+dsmKVoOpVRM9wEJ8bJ+td/uu+8+XLx4EYsWLcJLL72E+Ph4AMDcuXOxdOlSQQsMRDYnD4uDR1ykbwKQ4ziM0Cpxrt5MT4UQ4kX9CsDbb78dM2fO7LTM4XBAJpNh69atghQWyBotnmZ/nFLqs32maZT4/nIL6lvsPtsnIaGuX03gP/3pT12WrVy50uvFBItGs2cIjMZHV4AAMCzW8yRIRRM9FkeIt/R6BdjQ0AC9Xg+bzYaysrL2pxFaW1thtYbvL2KT2QERB6gVvrsCjIqQIC5SigpDaE2PRIg/9RqABw4cwNatW1FXV4ff/va37csjIyOxYcMGwYsLVE0WB9QKKcQi4XuAOxoaq0RpbTNcvBuA2Kf7JiQU9RqAS5YswZIlS/D5559j9uzZvqop4DWanT7rAOkoTaNASbUJZ+tboR0W6/P9ExJqeg3A7du3Y9GiRaipqcHrr7/eZf3q1asFKyxQuRmDweJsf0TNl4ZevQ94vNqEWygACbluvQZg230+i4XuO7UxWZ3gGYPGhz3AbZQyMeJVMhyrNvl834SEol4D8I477gDgeRaYeLTNyuKPJjAADNMocbymGXaXG3IJzWVByPXo12/Qs88+i9bWVjidTtxzzz2YNm0atm/fLnRtAanp6rt6ffUUyLWGaRRw8G6crG32y/4JCSX9CsCDBw9CpVKhqKgIycnJ+OKLL/Dqq68KXVtAajQ7oJCKoJT5pxc2Va2AiAO+qzL6Zf+EhJJ+BSDPe2YhKSoqQmFhIaKiun/FXDjwVw9wmwipGGlxkTheQ1eAhFyvfgXgbbfdhsLCQpSWlmL69OloamqCXC7sRKCBqsmHkyD0ZFxiFL6vbYbLTc8FE3I9+hWAGzduxD//+U9s2bIFUqkUCoUCL774otC1BZxWuwtmB4+4SN/3AHc0NikaVqcb5xta/VoHIcGu37N5lpeXo6ampr05DACLFy8WpKhAVWP0DAvy+xVgUgwA4OtKI3Sxnd8Wp5SKIfftAyqEBK1+BeCDDz6IqqoqZGVlQSz23PznOC7sAvCyyfMi9Fg/jAHsKEohRXSEBEVnGqC+ZkbqWVnxkPupg4aQYNOvADx58iQ+++wzn8x+HMjaAtCXkyD0JDkmAlVGKxhjYX9eCBmsfgVgZmYmGhoa2idC7Q+73Y677roLDocDPM9j9uzZWLdu3aALDQS1JhtUMjGkYv8PQE6NVeCUvhUmmysgApmQYNSvADQYDJg3bx4mTJgAqfSHX7aXXnqpx21kMhnefPNNREZGwul04s4778SMGTMwceLE66/aT2pNNqj93Pxtk6JWAACqjVYKQEIGqV8BuHbt2gF/McdxiIz0TBjgcrngcrmCvqlWa7IhMTowhv9oVTLIxCJUG20Ylxjt73IICUr9CsCbbroJNTU1qKiowM033wyr1dqpN7gnPM9j6dKlqKysxJ133ons7OxePy8Wc1Crlb1+xpfEYlF7PTYnjytmByakxECp6NoLLBGLul3e27rBbNO2TqWUY6hGgcsmW6fPRcilUMdE9Pu4QgUdU3AItGPqVwB+8MEHeP/992EymfDll19Cr9fj8ccfx5tvvtnrdmKxGNu3b0dzczPuu+8+nD17FiNHjuzx8zzPYDQGzswzarWyvZ7yRs8b2VRSESxWR5fPunh3t8t7WzeYbTquS4yS43yDGU3NVkRIPT2/NrsTRmPvL7DveFyhgo4pOPjrmLTa7p9e69fd/HfeeQfvvfceVCoVACAtLQ1NTU393nl0dDSmTp2K/fv393ubQFNtvNoD7OcxgB0lX70P2NY7TQgZmH4FoEwmg0z2wy++y+Xqc5umpiY0N3ueV7XZbPj666+Rnp4+yDL9r/rqIOhYRb/HjgsuKcZzP7KGApCQQenXb/OUKVPw0ksvwWaz4eDBg3j33XeRk5PT6zb19fV45JFHwPM8GGMoLCzErFmzvFK0P9QYbVBKxVBIA2eQsVzimSCVApCQwelXAG7cuBEfffQRRo4ciffffx8zZ87EihUret0mKysL27Zt80qRgaDaZEViTETA9WQnx0SgTN9KA6IJGYR+BaBIJEJeXh7y8vKg0WiErikgVRttGKoJnN6rNslqBUpqmnHF7IBWFRhDdAgJFr0GIGMMf/nLX/D222+3vxNYJBLhJz/5SVhNk8+7GS6bbJg2PPDCP/nqkJcao40CkJAB6rUT5I033kBxcTE++ugjHDlyBEeOHMGHH36IkpISvPHGGz4q0f/qW+1wuRkS+xhf5w+xSikUUjGqTeH7onpCBqvXANy+fTuee+45pKamti9LTU3FH/7wh5C6v9eXth7gpAAMQI7jkBwTgRojdYQQMlC9BqDL5er2np9Go+nXUJhQ0TYGMBCvAAEgWR2BJosTFkffT+cQQn7QawB2nPhgIOtCTbXRBomIC9h7bClXg5kGRBMyML12gpw+fRqTJ0/uspwxBoej+8e0QlGNyYqkmAiIRYE5zCQhJgIc56mTENJ/vQbgqVOnfFVHQKsx2gLy/l8bmVgEnUpO9wEJGSD/z+wZ4BhjqDZZ25uZgSpZHYHLzTbw9KY4QvqNArAPzTYXWu18+wSkgSo5RgEnz3Dp6qw1hJC+UQD2ofpqx0JyEFwBAkBpbYufKyEkeFAA9qHtVZiBfgUYEyFBpEyMU3UUgIT0FwVgH9pmWgnkThDAMyA6RR2BMroCJKTfKAD7UGO0QaOUQhkE79pNjlGgttmGJkv4DFEi5HpQAPah2mRFckxgN3/btN0H/P5ys58rISQ4UAD2ocZoQ4o6sJu/bRKi5JCIOJygACSkXygAe2F3uaFvsQd8D3AbiViEzHgVXQES0k8UgL24bLSCIfB7gDsanRCFMn0rnHzvb4YjhFAA9qqyyfP6vmC5AgSAsYlRsLvcOK1v9XcphAQ8CsBeVBk8ARgs9wABYFxSNACguNrk50oICXwUgL2obLJALhEhLjJw3gXcl1ilDMPjlPiuyujvUggJeBSAvahqsiI5AN8E15fJKTE4XtMMF02MQEivKAB7UdlkCar7f20mp8TA4uRxpp7uAxLSGwrAHjDGUGWwBlUPcJvJqWoAQDE1gwnpFQVgDxotTlidfFB1gLQZEinDsFgFdYQQ0od+vRh9MGpra/HQQw+hsbERHMfh9ttvxz333CPU7ryubRaYYHkM7lqTU2Pw79MN4N0sYKfyJ8TfBLsCFIvFeOSRR/DZZ5/h/fffx7vvvovz588LtTuva5sFJjkIrwABYHKKGmYHj7MNdB+QkJ4IFoDx8fEYO3YsAEClUiE9PR16vV6o3XldjdEGjgOSooM1AGMAAMVV1AwmpCeCNYE7qq6uxqlTp5Cdnd3r58RiDmq10hcl9ane4kRCdATih6jal1lNNigV3Y8JlIhFA143mG36Whchl0IdEwG1Wom0OCWO1bbgvmt+pmKxKGB+zt5CxxQcAu2YBA9As9mMdevW4Ve/+hVUKlWvn+V5BqPRInRJ/XKxoRWpsYpO9dgcPCzW7ufac/HuAa8bzDZ9rbPZnTAaPc8B35gSgx2letRfaYVM8sPFvlqtDJifs7fQMQUHfx2TVhvV7XJBe4GdTifWrVuHBQsWoKCgQMhdeV21yYahmsD5l2owpqVpYHO5aXosQnogWAAyxvDoo48iPT0dq1evFmo3grA5eTSaHUiNDe4AvCE1BmIRh0OXDP4uhZCAJFgAfvfdd9i+fTsOHz6MRYsWYdGiRfjqq6+E2p1Xtb0JLtivAFVyCSYkRePwpSZ/l0JIQBLsHuCNN96IM2fOCPX1gqoxegIwVROcYwA7ujktFn89cAn1LXbER8n9XQ4hAYWeBOlGjckzCDrYrwABYEZGHADgQHmjnyshJPBQAHaj2mhDpEwMtULq71Ku23CNEskxEdh3gZrBhFyLArAbFU0WDNMog24arO5wHIcZI+JwtNIAq5P3dzmEBBQKwG5UGKwYFhv89//azMyIg4NnOFhOV4GEdEQBeA2rk4e+xY6hIRSAE5NjEBcpwxdnGvxdCiEBhQLwGlUGTwfIsBDoAGkjFnHIzRyCgxebYHa4/F0OIQGDAvAaFW0BGEJXgACQP0oLu8uNfReoN5iQNhSA16i4+irMUGoCA8CE5GgkRMnxaWnwzMhDiNAoAK9RYbAiIUqOCKnY36V4lYjjsGCcDkcqjO2TvRIS7igAr1HRZAm5q782C8YlAAC2FFf7uRJCAgMFYAeMMVQarCHVAdJRYnQEpqbF4oNvq+Hk3f4uhxC/owDsoNHihNnBh1wHSEd3TEqGvsWOL8/SkBhCKAA7aOsAGRYCkyD0ZPrwWKQPicS739aAMXpxOglvFIAdVITgGMBriTgOa25Jw+n6Vnx9keYJJOGNArCDiiYL5BIRdCE+bdTiiclIionA3w5eoqtAEtYoADuoNFiRqlZAFAKTIPRGJhHhP6cPxZn6Vno8joQ1CsAOPD3AoXv/r6M5o3XIilfhT1+V0+NxJGxRAF7l5N2oMQb/LDAcx8Hg4Lv9Y+/Q2hWLODyUm4GGVgdeOljhv4IJ8SOfvBc4GFQZreBZ8HeAWF1uHDrXfbN2VlY85LIfnnAZnxSNFROT8M/iGvwoXYObhsX6qkxCAgJdAV514YpnCMyIIZF+rsS31s0YjjSNAo/tPIOGVru/yyHEpygArzp/xQwxB6QF+RXgQEVIxfjtgjGwOFzYsK0UtWZHj81mQkINBeBV5VfMSI1VQC4Jvx9JxpBIPJQ/Eqf1rVj3wXF8UVqHvafrsfd0PSw0jT4JYeH3296D81fMYdf87eiWEXGYN1aHS01WbDleC5ebnhUmoY8CEJ5p8GuMtrAOQACYkBSNOaPjUd5owUfHamF30dUfCW2CBeCmTZswffp0zJ8/X6hdeE15owUM4dcB0p2JKTGYOyYel5osePtoNXWMkJAmWAAuXboUf//734X6eq+60GAG4LkXFsraxgjWmmxdxgjyHTo7spNjcPukJBitLqz74ARK61r8VzQhAhJsHOCUKVNQXR0cE2+eqW+FUipGijrC36UIqm2MoFIhg8Xq6LRueqa209/T4yJx95QU7CjV495/HsPDeZlYeHVCVUJCRUANhBaLOajVvh+Gcr7JgjFJ0dDEdr4CFItFneqxmmxQKmTdfodELBrwusFs4411IhHX5TPdbZemkOH/Jqfgd7vO4KnPz6LcYMOv5mRBFoA95deeq1BAxyS8gApAnmcwGi2+3aeboexyMxaNT+iyb7Va2WmZzcF3uXJq4+LdA143mG28sa67K8CetlNIRNg8ZxReO1SBd45U4liVAf8zJwtxkTIopWLIA2TeiGvPVSigY/IerTaq2+WB90+5j1UarLC53MjSqfxdSkCyutzYd7YBGXFKLBqfgLP6Vvzn28X4x+EKGiNIgl7YB+Dpes8N/qz47v+FID8YkxCFVTelQiIW4Z1vq7HjZJ2/SyLkuggWgBs2bMAdd9yBixcvYsaMGfjwww+F2tV1OaM3Qy4RIS0ucO5LBLL4KDn+Y2oq0jRKvLD3Ap7+91k4XDRomgQnwe4BPv/880J9tVeV1jUjUxsJiShAbmYFAYVUjBWTklBptOG9b6txvsGM3y0YjYTo0O5FJ6EnrJvATt6NU/pWTEiK9ncpQUfEcVg9fRh+v3AMLjVZcPfbJThSQe8YIcElrAPwbIMZdpcb4xMpAAeD4zhMGhaLF26fgBiFBGu3fI8Xv65Ao91Fs8iQoBBQw2B87cTlZgCeiUHJwHWcfHV5dhI+K9Pj9UMVOHD+Cn6/ZBxSA/zlUnaGHnuyA2mIDxFOWAfg95eboYuSh/xb4HxBJhFh0fgEJKtN2HO2Afe/fxx/XDQGmdrAHV5kcfLYe7q+23XXzp5NQlPYNoEZYzhxuZmav17EcRymDFXjrhtTYHPxWP3uMXxWpvd3WYT0KGwDsMZkg77FjkkpMf4uJeSkqBV4ceVEjEmIwuM7z+B3X56D3U9DZewMPb4kiqf7lGEvbJvARyqNAICbhqr9XElo0kTK8OLy8fjrgUt4+9tqnLjcjGfmjcZwH4+3vLaZ6+LdqGux47LJBrFYhIpGM2wuN8QcB4VMDJVMDK1KjvR4FaLjVRDT8KiQFrYBeLTCCK1KFjbvAfYHiViE9TPTceNQNZ7ceQar3i7GxpwRWDguAZwPXz7PuxnKG80orW3BuQYzXG7PpZ9aIYVExCFCKoLd7UaTxYFWOw+Xm2FHqR4xERJMS4vFzcM1mDEiDip52P66hKywPKNuxvBtlRE3D4/16S9iuLpluAbvrpqMx3aewdP/PodDFUbcPzMdkd0EymB6X+0MqDXZYHN07tHl3QxfnG7Aa19XwGh1QiEVYXxSNNLjlEiKiUD+uMQurxB1uxkaLQ6oI+U4ddmEQ5cM+Px0A6RiDrcM1yB/lBYzRsQhQkodJKEgLAPwXL0ZRqsTU6j5K5i2yVfbiGUS/HrBGHxQXIM3D1fg2woD5o7RdXkEcTC9rxYnj28qGttns2GM4ZS+FfsvNKLJ4oQuSo6l2YnIGBLZZ5NWJOKgVckxKyseK7MT4WYMpbUt+OJMA74404Ci841QSEWYMSIOBVnxmJ4WC6k4bG+lB72wDMCvLlwBB+Dm4Rp/lxKyenpBe4JKht8tGY/f7TqN94prMCk5GrdlDvHKFRVjDGfrzdhf3oiGVge0Khk2FY4Cc/EDvtLvGOApQyKxekgkVk0fhpOXm3HgQiOKzjbg89MNiImQIG+UFoVZ8ZiQHA0RtSiCSlgGYNH5RmQnR0Oj7H7iUCKsrIQo/HTaUOy70IgjFUacaTDjtoy4QQ9IZ4zhTF0Lvjilh77FDo1SikXjEzBap8L09Lhug7gvPQU4ANx/2wjce2savqs0Ys+ZBuwo1WPL8VroouTIz4rHvDHx3b5eoaeB1zTo2n/CLgBrTFacazDjgZnp/i4lrNsyHcoAAA+ASURBVEnFIuSO1GJMQhS+PNOAz8rq8W2lERBxWDxGB0k/mpUuN8PuMw147UgVyq+YoVZIMX+sDmMToiASsPfWE45XAADT02IxOSUGZ+tbUVrXgne/rcLbR6uQqY1EYVY8CrK07ZNE9DTwmgZd+0/YBeDec40AgJkZcX6uhABAYnQEfnJjCk7pW3GgvBG///c5vP51BeaP1eGW9Dhkxas6TcFvc/L4vrYZe85ewd7zjWg0O5Aaq8CSiUnIjFP6ZdiKXOLpXBmfFI2JQ9U4Wt6EXafr8b/7L+J/91/EpJQYzB+rw9QR9P9coAmrAGSMYUdpHcYmRCFFTcNfAgXHcRiTEIXROhVUCil2nKjDm0eq8No3VRBzgFYlR4RUBIuDxxWzA27mCZ1b0zWYM1qHcakxOFpp6vFVAL4Uq5Rh5eRkrJycjGqjFbtO1WPXqXo89flZaJRSjEuMxg2pMdSLHCDCKgBP6Vtx4YoFm/Iy/F0K6QbHcbgpTYPZI7UwWpworjHhjL4FdS12OFxuKKRiJETLMSo+CjcNU0NxNUQMjsCZmr9j50mkUoZlN6Rg6eRkFFeZ8FFJjee+Z6UB09M0uCE1hnqQ/SysAvCTk3WQS0QoyIr3dymkD2qlFDmZQ5CTOcTfpQxIb50nj88fg4+/q8JX5xux99wVfFtpRO7IIbhtlLbbzxPhhc0/P0aLE5+W6pE3Sksj+onfJERHYOXkZNx1YwqUMjG2fV+Hh7eVorzR7O/SwlLYBOA/S2pgd7lxz5RUf5dCCIbGKvAfU1NRkKXF+YZW3PlWMf78VTksAdScDwdhEYBGqxMflFzGzIw4nz+MT0hPRByHG1LVeO3uGzB/jA5vf1uNFa8fxZ6zDWCMpqrxhbAIwBcPXITF4cLPb0nzdymkD22dCN39CdVp9tUKKf5n9ki8+uOJiFFI8fC/TmH91pOooGax4EL+ZtixahO2najDj29I7nZ0PgksvXUi5IzWwdLNlVGozOs3ISkab/1kMj48dhkvH7yEuX85iLtvTMFPbkyh+9YCCemf6hWzA5t2nEKKOgL33jzM3+WQ69RTOE7PDO5e1Gsnjigcl4ApabH4+6FKvHq4Eh8du4zVU4diaXZi+9Af4h0hG4AGiwPrtnyPFrsL/7tsEiJlIXuoJMj1FOy3jdRiyYQE/OObSvzpq3K89k0lFo1LwPKJSUiKoXcwe0NIpsIpfQse3XEK9a0OPLdoLDK01PQlwWmkLgp/WT4Bx2tMeK+4Bu98V41/fFuN8YlRyB2pxfThsRiuUdK8loMkaADu27cPzzzzDNxuN1asWIF7771XyN3hUqMF7xZX45Pv6xAXKcNfl49HdjK984MEv+zkGGQnx6Cu2Yadp+rx5ZkG/OmrcvzpKyAmQoLxSdEYrlEiTaOELkoOtVKKWIUUsUopPW3SC8ECkOd5/PrXv8brr78OnU6H5cuXIycnBxkZ3nkMzc0YjlYaUdFkwaUmK0qqTTh/xQyJiMOy7CTce/MwxCikXtkXIf5y7f1BeYQUiyclY/GkZBjMDpysMeFYtQll+hZ8U2GAs5seIREHSEQcJCIRpGIOYhHXPm8hxwFch30Bnr+3L+/hylJ89VUCCqkYKpkESqkYSpnn70qZGAqp50+ERIQIqRgKqQgREjGGxNrhsjvbl8vFIohEnu8Tc566RCIOYg4+uaoVLABPnDiBYcOGITXVM/B43rx52L17t9cCcNepejy+8wwAIFImxpiEKDwwMx2zR8djSCTN80dCQ2+94rOy4rFwXAIWjksA4HkFQG2zDVdaHai3OKFvtaPZ6oSDd4PnGZxuBt7N4GbM814UBjAwMAC4mpscx4F3X116dRkD4GaAvtmGtiVuBjh5NwxmJywOHk6XG1YnD4uTh9VLb9wTcZ6xkqIOYSjigAdmpmNpdtL17wAAxwQacblr1y7s378fzzzzDABg27ZtOHHiBB577DEhdkcIIQNGNwcIIWFLsADU6XSoq6tr/7ter4dOpxNqd4QQMmCCBeD48eNx6dIlVFVVweFw4NNPP0VOTo5QuyOEkAETrBNEIpHgsccew89+9jPwPI9ly5YhMzNTqN0RQsiACdYJQgghgY46QQghYYsCkBAStigAe7Bv3z7Mnj0b+fn5eOWVV/xdThe1tbW4++67MXfuXMybNw9vvvkmAMBoNGL16tUoKCjA6tWrYTKZAHjeiPf0008jPz8fCxYsQGlpaft3ffzxxygoKEBBQQE+/vjj9uUnT57EggULkJ+fj6efftpnk3TyPI/Fixfj5z//OQCgqqoKK1asQH5+Ph544AE4HJ63vzkcDjzwwAPIz8/HihUrUF1d3f4dL7/8MvLz8zF79mzs37+/fbk/zmtzczPWrVuHwsJCzJkzByUlJUF/nt544w3MmzcP8+fPx4YNG2C324PzPDHShcvlYrm5uayyspLZ7Xa2YMECdu7cOX+X1Yler2cnT55kjDHW0tLCCgoK2Llz59jvf/979vLLLzPGGHv55ZfZs88+yxhjrKioiK1Zs4a53W5WUlLCli9fzhhjzGAwsJycHGYwGJjRaGQ5OTnMaDQyxhhbtmwZKykpYW63m61Zs4YVFRX55Nhee+01tmHDBnbvvfcyxhhbt24d27FjB2OMsc2bN7N33nmHMcbY22+/zTZv3swYY2zHjh1s/fr1jDHGzp07xxYsWMDsdjurrKxkubm5zOVy+e28PvTQQ+yDDz5gjDFmt9uZyWQK6vNUV1fHZs2axaxWK2PMc362bNkSlOeJrgC70fExPplM1v4YXyCJj4/H2LFjAQAqlQrp6enQ6/XYvXs3Fi9eDABYvHgxvvzySwBoX85xHCZOnIjm5mbU19fjwIEDuOWWW6BWqxETE4NbbrkF+/fvR319PVpbWzFx4kRwHIfFixf75GdQV1eHoqIiLF++HIDniujw4cOYPXs2AGDJkiXtdezZswdLliwBAMyePRuHDh0CYwy7d+/GvHnzIJPJkJqaimHDhuHEiRN+Oa8tLS04evRo+/HIZDJER0cH/XnieR42mw0ulws2mw1arTYozxMFYDf0ej0SEhLa/67T6aDX6/1YUe+qq6tx6tQpZGdno7GxEfHxntd+arVaNDY2Auh6TAkJCdDr9T0ea0+fF9pvfvMbPPjggxCJPP9rGgwGREdHQyKRdKlDr9cjMTERgGfYVVRUFAwGQ7+PyRfntbq6GhqNBps2bcLixYvx6KOPwmKxBPV50ul0+OlPf4pZs2bh1ltvhUqlwtixY4PyPFEABjmz2Yx169bhV7/6FVQqVad1HMcF1Txxe/fuhUajwbhx4/xdite4XC6UlZXhxz/+MbZt2waFQtHlnlawnSeTyYTdu3dj9+7d2L9/P6xWa6f7d8GEArAbwfIYn9PpxLp167BgwQIUFBQAAOLi4lBfXw8AqK+vh0ajAdD1mOrq6qDT6Xo81p4+L6Ti4mLs2bMHOTk52LBhAw4fPoxnnnkGzc3NcLlcXerQ6XSora0F4AmalpYWxMbG9vuYfHFeExISkJCQgOzsbABAYWEhysrKgvo8ff3110hJSYFGo4FUKkVBQQGKi4uD8jxRAHYjGB7jY4zh0UcfRXp6OlavXt2+PCcnB9u2bQPgmYEnNze303LGGI4dO4aoqCjEx8fj1ltvxYEDB2AymWAymXDgwAHceuutiI+Ph0qlwrFjx8AY6/RdQvnlL3+Jffv2Yc+ePXj++ecxbdo0PPfcc5g6dSo+//xzAJ6e0LZzkZOT094b+vnnn2PatGngOA45OTn49NNP4XA4UFVVhUuXLmHChAl+Oa9arRYJCQkoLy8HABw6dAgjRowI6vOUlJSE48ePw2q1gjGGQ4cOISMjIzjPkyBdKyGgqKiIFRQUsNzcXPbiiy/6u5wujh49ykaOHMnmz5/PFi5cyBYuXMiKiopYU1MTW7VqFcvPz2f33HMPMxgMjDHG3G43e+KJJ1hubi6bP38+O3HiRPt3ffjhhywvL4/l5eWxjz76qH35iRMn2Lx581hubi578sknmdvt9tnxHT58uL0XuLKyki1btozl5eWxtWvXMrvdzhhjzGazsbVr17K8vDy2bNkyVllZ2b79iy++yHJzc1lBQUGnXlF/nNeysjK2ZMkSNn/+fPaLX/yCGY3GoD9Pf/7zn9ns2bPZvHnz2MaNG9t7coPtPNGjcISQsEVNYEJI2KIAJISELQpAQkjYogAkhIQtCkBCSNiiACR+9cgjj2DXrl3+LoOEKQpAErQYY3C73f4ugwQxGgdIfGrbtm149dVXwXEcRo0aBbFYDJVKhZMnT6KhoQEPPvggCgsLYTab8d///d/tj1etX78eeXl5qK6uxpo1a5CdnY3S0lK88sor2LZtGz755BNoNBokJiZi7NixWLNmDSorK/Hkk0/CYDAgIiICTz31FEaMGIGdO3fir3/9K0QiEaKiovDOO+/4+8dC/EWwIdaEXOPs2bOsoKCANTY2MsY8c9w9/PDDbO3atYzneXbu3DmWl5fHGGPM6XSylpYWxhhjjY2NLC8vj7ndblZVVcVGjRrFSkpKGGOMHT9+nC1cuJDZbDbW0tLC8vPz2d///nfGGGOrVq1iFy9eZIwxduzYMXb33XczxhibP38+q6urY4wxZjKZfHb8JPAI9lY4Qq51+PBhFBYWtj/4r1arAQB5eXkQiUTIyMjAlStXAHiat88//zyOHj0KkUgEvV7fvi4pKQkTJ04E4JlAITc3F3K5HHK5HLNmzQLgmSWnpKQE69evb99/2wzFkyZNwiOPPII5c+YgPz/fNwdPAhIFIPE7mUzWZdm//vUvNDU1YevWrZBKpcjJyYHdbgcAKJXKPr+TMYbo6Ghs3769y7pf//rXOH78OIqKirBs2TJs2bIFsbGx138gJOhQJwjxmWnTpmHXrl0wGAwAPO8v6UlLSwvi4uIglUpx+PBh1NTUdPu5yZMnY+/evbDb7TCbzSgqKgLgmSU7JSUFO3fuBOAJxNOnTwMAKisrkZ2djfXr1yM2NrbT1EskvNAVIPGZzMxM/Nd//RfuvvtuiEQijBkzpsfPLliwAL/4xS+wYMECjBs3Dunp6d1+bsKECcjJycHChQsRFxeHkSNHIioqCgDwhz/8AU888QT+9re/weVyYe7cucjKysKzzz6LiooKMMYwbdo0ZGVlCXK8JPBRLzAJemazGZGRkbBarbjrrrvw1FNPtb8vhZDe0BUgCXqPPfYYzp8/D7vdjiVLllD4kX6jK0BCSNiiThBCSNiiACSEhC0KQEJI2KIAJISELQpAQkjY+n+zNT2dm265kwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueCHIeP2zAmN"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8oeEgxNzAmN"
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EURnXXnczAmN"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRzaICNozAmN",
        "outputId": "807503b9-7ae5-485e-ff7a-50fd0a2c4702"
      },
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array, targets_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[18.     ,  0.     , 23.3673 ,  1.     ,  0.     ,  2.     ],\n",
              "        [22.     ,  1.     , 36.4914 ,  1.     ,  1.     ,  2.     ],\n",
              "        [45.     ,  1.     , 29.58015,  2.     ,  0.     ,  1.     ],\n",
              "        ...,\n",
              "        [26.     ,  0.     , 33.174  ,  2.     ,  0.     ,  3.     ],\n",
              "        [23.     ,  1.     , 31.5832 ,  0.     ,  0.     ,  2.     ],\n",
              "        [31.     ,  0.     , 25.026  ,  2.     ,  0.     ,  3.     ]]),\n",
              " array([[ 2619.305549 ],\n",
              "        [44226.544922 ],\n",
              "        [10012.0210295],\n",
              "        ...,\n",
              "        [ 4745.63194  ],\n",
              "        [ 2170.899626 ],\n",
              "        [ 5872.29895  ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbzjnIAVzAmO"
      },
      "source": [
        "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Q6tZY4zAmO"
      },
      "source": [
        "inputs = torch.from_numpy(inputs_array).float()\n",
        "targets = torch.from_numpy(targets_array).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRDYqLNRzAmO",
        "outputId": "d6cadd01-e0c6-445b-d305-b80e95d97ce5"
      },
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_XIgHTzAmO"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu4YbFU8zAmP"
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Of0CSrnzAmP"
      },
      "source": [
        "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqi_zrplzAmP"
      },
      "source": [
        "val_percent = 0.1 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BG0bnbUzAmQ"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ijUuAizAmQ"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI0JOwVczAmQ"
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaSa1Lr4zAmQ"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKxQsGEXzAmR",
        "outputId": "40439b87-59a0-44ec-d6e8-1418d3645cf2"
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[61.0000,  1.0000, 37.2286,  0.0000,  0.0000,  1.0000],\n",
            "        [61.0000,  0.0000, 37.9270,  2.0000,  0.0000,  3.0000],\n",
            "        [41.0000,  0.0000, 27.2085,  1.0000,  0.0000,  2.0000],\n",
            "        [50.0000,  1.0000, 31.1467,  2.0000,  0.0000,  0.0000],\n",
            "        [46.0000,  0.0000, 29.8760,  3.0000,  0.0000,  3.0000],\n",
            "        [39.0000,  0.0000, 33.0770,  3.0000,  0.0000,  3.0000],\n",
            "        [52.0000,  0.0000, 22.4846,  0.0000,  0.0000,  0.0000],\n",
            "        [51.0000,  0.0000, 25.0260,  1.0000,  0.0000,  3.0000],\n",
            "        [19.0000,  0.0000, 23.8668,  1.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  1.0000, 24.4198,  0.0000,  0.0000,  1.0000],\n",
            "        [42.0000,  1.0000, 25.5256,  1.0000,  0.0000,  1.0000],\n",
            "        [35.0000,  1.0000, 33.7269,  2.0000,  0.0000,  1.0000],\n",
            "        [60.0000,  0.0000, 29.5850,  0.0000,  0.0000,  3.0000],\n",
            "        [48.0000,  1.0000, 28.7120,  0.0000,  0.0000,  3.0000],\n",
            "        [51.0000,  1.0000, 31.3310,  1.0000,  0.0000,  0.0000],\n",
            "        [44.0000,  0.0000, 37.7815,  0.0000,  1.0000,  1.0000],\n",
            "        [36.0000,  1.0000, 33.3971,  0.0000,  1.0000,  2.0000],\n",
            "        [50.0000,  1.0000, 35.9579,  1.0000,  0.0000,  2.0000],\n",
            "        [64.0000,  1.0000, 35.8512,  2.0000,  1.0000,  2.0000],\n",
            "        [37.0000,  1.0000, 28.9351,  2.0000,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 39.2850,  0.0000,  0.0000,  3.0000],\n",
            "        [38.0000,  1.0000, 28.3822,  2.0000,  0.0000,  1.0000],\n",
            "        [46.0000,  1.0000, 39.1637,  2.0000,  0.0000,  1.0000],\n",
            "        [28.0000,  0.0000, 23.1297,  2.0000,  0.0000,  1.0000],\n",
            "        [57.0000,  1.0000, 32.6211,  1.0000,  0.0000,  1.0000],\n",
            "        [41.0000,  1.0000, 33.1837,  1.0000,  0.0000,  2.0000],\n",
            "        [38.0000,  0.0000, 26.7720,  0.0000,  0.0000,  3.0000],\n",
            "        [61.0000,  1.0000, 32.5289,  0.0000,  0.0000,  0.0000],\n",
            "        [43.0000,  1.0000, 19.5261,  2.0000,  1.0000,  2.0000],\n",
            "        [30.0000,  1.0000, 23.6680,  3.0000,  1.0000,  3.0000],\n",
            "        [26.0000,  0.0000, 33.1740,  2.0000,  0.0000,  3.0000],\n",
            "        [56.0000,  0.0000, 36.3847,  2.0000,  0.0000,  2.0000],\n",
            "        [48.0000,  0.0000, 28.0330,  0.0000,  0.0000,  3.0000],\n",
            "        [41.0000,  0.0000, 30.0894,  0.0000,  0.0000,  2.0000],\n",
            "        [37.0000,  1.0000, 29.9487,  3.0000,  0.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 40.9728,  0.0000,  1.0000,  2.0000],\n",
            "        [47.0000,  1.0000, 27.3685,  4.0000,  0.0000,  0.0000],\n",
            "        [30.0000,  1.0000, 36.3071,  3.0000,  0.0000,  0.0000],\n",
            "        [56.0000,  1.0000, 32.6211,  0.0000,  1.0000,  1.0000],\n",
            "        [34.0000,  1.0000, 31.8160,  1.0000,  0.0000,  3.0000],\n",
            "        [60.0000,  0.0000, 26.7235,  0.0000,  0.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 32.3447,  2.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 28.0136,  0.0000,  1.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 28.2901,  0.0000,  0.0000,  0.0000],\n",
            "        [33.0000,  1.0000, 22.0238,  0.0000,  0.0000,  1.0000],\n",
            "        [21.0000,  0.0000, 31.6996,  2.0000,  0.0000,  1.0000],\n",
            "        [29.0000,  0.0000, 24.8320,  4.0000,  0.0000,  3.0000],\n",
            "        [48.0000,  0.0000, 22.1160,  0.0000,  0.0000,  3.0000],\n",
            "        [22.0000,  0.0000, 29.4880,  0.0000,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 16.7713,  2.0000,  1.0000,  0.0000],\n",
            "        [33.0000,  0.0000, 37.7330,  3.0000,  0.0000,  3.0000],\n",
            "        [26.0000,  1.0000, 22.9890,  2.0000,  0.0000,  3.0000],\n",
            "        [24.0000,  1.0000, 31.7190,  0.0000,  1.0000,  3.0000],\n",
            "        [36.0000,  0.0000, 29.0224,  0.0000,  0.0000,  2.0000],\n",
            "        [37.0000,  1.0000, 29.8760,  0.0000,  0.0000,  3.0000],\n",
            "        [31.0000,  0.0000, 28.3822,  1.0000,  0.0000,  2.0000],\n",
            "        [27.0000,  1.0000, 27.6450,  0.0000,  1.0000,  1.0000],\n",
            "        [58.0000,  1.0000, 27.7372,  0.0000,  0.0000,  1.0000],\n",
            "        [27.0000,  1.0000, 31.6899,  0.0000,  0.0000,  2.0000],\n",
            "        [44.0000,  0.0000, 26.8157,  0.0000,  0.0000,  1.0000],\n",
            "        [54.0000,  1.0000, 29.3037,  0.0000,  0.0000,  1.0000],\n",
            "        [43.0000,  0.0000, 33.5426,  1.0000,  0.0000,  1.0000],\n",
            "        [32.0000,  0.0000, 17.2320,  2.0000,  1.0000,  1.0000],\n",
            "        [21.0000,  0.0000, 21.2333,  2.0000,  0.0000,  2.0000],\n",
            "        [27.0000,  0.0000, 34.9976,  0.0000,  1.0000,  2.0000],\n",
            "        [19.0000,  1.0000, 24.7883,  1.0000,  0.0000,  1.0000],\n",
            "        [44.0000,  0.0000, 35.8464,  1.0000,  0.0000,  1.0000],\n",
            "        [41.0000,  0.0000, 31.2340,  1.0000,  0.0000,  3.0000],\n",
            "        [50.0000,  1.0000, 24.6040,  2.0000,  0.0000,  1.0000],\n",
            "        [52.0000,  0.0000, 30.7781,  2.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 31.1467,  0.0000,  0.0000,  1.0000],\n",
            "        [41.0000,  0.0000, 27.4607,  1.0000,  0.0000,  1.0000],\n",
            "        [63.0000,  1.0000, 40.0853,  3.0000,  0.0000,  1.0000],\n",
            "        [29.0000,  1.0000, 27.1018,  0.0000,  0.0000,  2.0000],\n",
            "        [18.0000,  0.0000, 37.1316,  0.0000,  0.0000,  2.0000],\n",
            "        [61.0000,  1.0000, 22.9454,  0.0000,  0.0000,  0.0000],\n",
            "        [56.0000,  0.0000, 38.6254,  0.0000,  0.0000,  2.0000],\n",
            "        [25.0000,  1.0000, 44.1738,  2.0000,  1.0000,  2.0000],\n",
            "        [23.0000,  0.0000, 30.4580,  0.0000,  1.0000,  3.0000],\n",
            "        [55.0000,  0.0000, 29.5850,  0.0000,  0.0000,  3.0000],\n",
            "        [54.0000,  1.0000, 20.3797,  2.0000,  0.0000,  2.0000],\n",
            "        [19.0000,  1.0000, 33.7560,  0.0000,  1.0000,  3.0000],\n",
            "        [18.0000,  0.0000, 26.4616,  3.0000,  1.0000,  2.0000],\n",
            "        [48.0000,  0.0000, 31.3310,  2.0000,  0.0000,  0.0000],\n",
            "        [43.0000,  0.0000, 31.5832,  3.0000,  1.0000,  2.0000],\n",
            "        [44.0000,  0.0000, 19.6280,  1.0000,  1.0000,  0.0000],\n",
            "        [48.0000,  0.0000, 35.4777,  0.0000,  0.0000,  1.0000],\n",
            "        [28.0000,  1.0000, 26.1706,  2.0000,  0.0000,  0.0000],\n",
            "        [26.0000,  1.0000, 45.1341,  1.0000,  0.0000,  2.0000],\n",
            "        [51.0000,  0.0000, 20.9132,  1.0000,  0.0000,  2.0000],\n",
            "        [39.0000,  1.0000, 28.7120,  4.0000,  0.0000,  3.0000],\n",
            "        [38.0000,  1.0000, 27.4219,  1.0000,  0.0000,  2.0000],\n",
            "        [22.0000,  1.0000, 35.9579,  2.0000,  1.0000,  2.0000],\n",
            "        [48.0000,  1.0000, 38.9455,  0.0000,  0.0000,  2.0000],\n",
            "        [57.0000,  0.0000, 27.8390,  0.0000,  0.0000,  3.0000],\n",
            "        [42.0000,  0.0000, 40.0853,  1.0000,  0.0000,  0.0000],\n",
            "        [24.0000,  0.0000, 22.5137,  0.0000,  0.0000,  2.0000],\n",
            "        [18.0000,  0.0000, 30.4095,  0.0000,  0.0000,  2.0000],\n",
            "        [18.0000,  0.0000, 23.3673,  1.0000,  0.0000,  2.0000],\n",
            "        [45.0000,  0.0000, 38.7952,  3.0000,  0.0000,  0.0000],\n",
            "        [59.0000,  0.0000, 26.6750,  0.0000,  0.0000,  3.0000],\n",
            "        [61.0000,  1.0000, 32.8975,  0.0000,  0.0000,  0.0000],\n",
            "        [22.0000,  0.0000, 26.2870,  0.0000,  0.0000,  3.0000],\n",
            "        [26.0000,  0.0000, 16.6791,  2.0000,  1.0000,  0.0000],\n",
            "        [25.0000,  0.0000, 23.5710,  3.0000,  0.0000,  3.0000],\n",
            "        [54.0000,  1.0000, 30.6520,  0.0000,  0.0000,  3.0000],\n",
            "        [49.0000,  0.0000, 33.7269,  1.0000,  0.0000,  1.0000],\n",
            "        [34.0000,  0.0000, 22.8532,  0.0000,  0.0000,  0.0000],\n",
            "        [53.0000,  1.0000, 30.4095,  0.0000,  0.0000,  2.0000],\n",
            "        [64.0000,  1.0000, 37.0443,  0.0000,  0.0000,  0.0000],\n",
            "        [54.0000,  0.0000, 30.9430,  1.0000,  0.0000,  2.0000],\n",
            "        [46.0000,  0.0000, 26.8884,  1.0000,  0.0000,  2.0000],\n",
            "        [47.0000,  0.0000, 32.8975,  3.0000,  0.0000,  1.0000],\n",
            "        [38.0000,  1.0000, 37.2383,  3.0000,  1.0000,  2.0000],\n",
            "        [49.0000,  1.0000, 35.7445,  0.0000,  0.0000,  2.0000],\n",
            "        [27.0000,  1.0000, 32.1604,  2.0000,  0.0000,  1.0000],\n",
            "        [23.0000,  0.0000, 31.7966,  2.0000,  1.0000,  2.0000],\n",
            "        [21.0000,  1.0000, 24.9290,  4.0000,  1.0000,  3.0000],\n",
            "        [41.0000,  1.0000, 31.2340,  2.0000,  0.0000,  3.0000],\n",
            "        [22.0000,  1.0000, 30.4095,  1.0000,  0.0000,  1.0000],\n",
            "        [29.0000,  0.0000, 25.2491,  0.0000,  0.0000,  1.0000],\n",
            "        [40.0000,  1.0000, 24.2209,  2.0000,  0.0000,  2.0000],\n",
            "        [45.0000,  0.0000, 37.1365,  0.0000,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 15.4812,  0.0000,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 22.3925,  0.0000,  0.0000,  0.0000],\n",
            "        [64.0000,  0.0000, 31.9760,  0.0000,  0.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 31.1564,  2.0000,  0.0000,  2.0000],\n",
            "        [49.0000,  0.0000, 20.6610,  1.0000,  0.0000,  3.0000]])\n",
            "targets: tensor([[15410.5850],\n",
            "        [16939.7363],\n",
            "        [ 8056.5293],\n",
            "        [30146.6660],\n",
            "        [11203.7549],\n",
            "        [ 8828.0410],\n",
            "        [12135.3486],\n",
            "        [11734.6201],\n",
            "        [ 3224.0002],\n",
            "        [ 1942.1232],\n",
            "        [ 8259.6826],\n",
            "        [ 6817.5161],\n",
            "        [15039.4521],\n",
            "        [25266.2969],\n",
            "        [11857.2314],\n",
            "        [51150.3164],\n",
            "        [44913.6641],\n",
            "        [10767.1523],\n",
            "        [58997.4180],\n",
            "        [ 7623.6289],\n",
            "        [ 2093.6123],\n",
            "        [ 7684.8335],\n",
            "        [10392.5430],\n",
            "        [ 5616.4863],\n",
            "        [14214.7080],\n",
            "        [ 7484.8081],\n",
            "        [ 6406.4077],\n",
            "        [15640.5703],\n",
            "        [22333.6074],\n",
            "        [21728.4668],\n",
            "        [ 4745.6318],\n",
            "        [14595.9531],\n",
            "        [ 9850.2520],\n",
            "        [ 7360.5317],\n",
            "        [ 8088.2671],\n",
            "        [46163.2969],\n",
            "        [12384.4326],\n",
            "        [ 6460.1860],\n",
            "        [52266.2070],\n",
            "        [17086.4531],\n",
            "        [15728.3428],\n",
            "        [23136.4004],\n",
            "        [21120.7227],\n",
            "        [ 8715.2441],\n",
            "        [26161.5195],\n",
            "        [30962.5508],\n",
            "        [ 6793.5518],\n",
            "        [ 9840.1621],\n",
            "        [ 3262.9182],\n",
            "        [15267.0518],\n",
            "        [ 7107.1299],\n",
            "        [ 4146.3540],\n",
            "        [41022.6797],\n",
            "        [ 5817.9536],\n",
            "        [ 5529.6431],\n",
            "        [ 5177.1123],\n",
            "        [21789.7832],\n",
            "        [13965.6963],\n",
            "        [ 2971.4756],\n",
            "        [ 8831.2217],\n",
            "        [12175.4854],\n",
            "        [ 9195.4316],\n",
            "        [38953.6836],\n",
            "        [ 3784.8071],\n",
            "        [44189.3398],\n",
            "        [ 2643.6616],\n",
            "        [ 9547.5312],\n",
            "        [ 8063.3936],\n",
            "        [36038.7266],\n",
            "        [13313.3115],\n",
            "        [ 2535.5044],\n",
            "        [ 8512.7295],\n",
            "        [18510.6738],\n",
            "        [ 3411.8723],\n",
            "        [16818.3145],\n",
            "        [15624.2285],\n",
            "        [13197.9541],\n",
            "        [50113.5586],\n",
            "        [40657.8633],\n",
            "        [12738.3193],\n",
            "        [13106.3174],\n",
            "        [41387.7422],\n",
            "        [21685.9062],\n",
            "        [11951.4668],\n",
            "        [48720.1289],\n",
            "        [23317.8242],\n",
            "        [10318.7178],\n",
            "        [ 5277.7622],\n",
            "        [ 3483.2070],\n",
            "        [11727.6064],\n",
            "        [ 8939.5977],\n",
            "        [ 6526.5161],\n",
            "        [44606.4961],\n",
            "        [ 9286.9512],\n",
            "        [13631.7832],\n",
            "        [ 9104.4209],\n",
            "        [29847.3047],\n",
            "        [ 1930.4043],\n",
            "        [ 2619.3057],\n",
            "        [11548.5547],\n",
            "        [14558.2549],\n",
            "        [15641.1992],\n",
            "        [ 2563.6897],\n",
            "        [17202.2168],\n",
            "        [ 5226.0659],\n",
            "        [11722.0137],\n",
            "        [11404.8330],\n",
            "        [ 5940.9277],\n",
            "        [32541.7910],\n",
            "        [17149.0098],\n",
            "        [13005.3301],\n",
            "        [ 9796.8398],\n",
            "        [12036.8604],\n",
            "        [49919.6016],\n",
            "        [ 9669.6836],\n",
            "        [ 4829.8677],\n",
            "        [42865.0039],\n",
            "        [21351.1055],\n",
            "        [ 8182.3936],\n",
            "        [ 3145.4895],\n",
            "        [ 4446.3931],\n",
            "        [ 7846.2749],\n",
            "        [ 9442.9961],\n",
            "        [ 2016.8077],\n",
            "        [ 2028.5931],\n",
            "        [17484.2773],\n",
            "        [ 3333.4980],\n",
            "        [10926.7822]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfjTmLF-zAmS"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uk9iqBdzAmS"
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL0j3g7izAmV"
      },
      "source": [
        "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOruroQPzAmW"
      },
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)  # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)    # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        loss = F.l1_loss(out, targets)          # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)    # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8zlfJeTzAmW"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2nd--QPzAmW"
      },
      "source": [
        "model = InsuranceModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oXSaKjPzAmW"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9YnT39-zAmW",
        "outputId": "57906ae0-bd26-4e29-9210-c671730c9373"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0568,  0.2454, -0.3191,  0.1978, -0.3161,  0.1013]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([0.0274], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7PxRoW-zAmY"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBFYitqzAmY"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtZFB7rUzAmY"
      },
      "source": [
        "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zq3jcydzAmY",
        "outputId": "6e2aeb98-355c-471c-b3ae-9f85ff10de94"
      },
      "source": [
        "result = evaluate(model,val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 14403.748046875}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii1lxwKKzAmY"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjsW_mrRzAmY"
      },
      "source": [
        "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnMt7KMwzAmZ",
        "outputId": "c39371f5-1a1e-4102-ff40-66ff320ee5f0"
      },
      "source": [
        "epochs = 500\n",
        "lr = 5e-1\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6292.1191\n",
            "Epoch [40], val_loss: 6246.1021\n",
            "Epoch [60], val_loss: 6263.2314\n",
            "Epoch [80], val_loss: 6218.1035\n",
            "Epoch [100], val_loss: 6220.0010\n",
            "Epoch [120], val_loss: 6227.4849\n",
            "Epoch [140], val_loss: 6185.6182\n",
            "Epoch [160], val_loss: 6175.2554\n",
            "Epoch [180], val_loss: 6175.2275\n",
            "Epoch [200], val_loss: 6171.0410\n",
            "Epoch [220], val_loss: 6180.6406\n",
            "Epoch [240], val_loss: 6166.2295\n",
            "Epoch [260], val_loss: 6144.6890\n",
            "Epoch [280], val_loss: 6126.6318\n",
            "Epoch [300], val_loss: 6139.1929\n",
            "Epoch [320], val_loss: 6128.3052\n",
            "Epoch [340], val_loss: 6129.2349\n",
            "Epoch [360], val_loss: 6097.0537\n",
            "Epoch [380], val_loss: 6100.3662\n",
            "Epoch [400], val_loss: 6082.9365\n",
            "Epoch [420], val_loss: 6101.5508\n",
            "Epoch [440], val_loss: 6076.3389\n",
            "Epoch [460], val_loss: 6086.3306\n",
            "Epoch [480], val_loss: 6070.7451\n",
            "Epoch [500], val_loss: 6057.4238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBGvYT2rzAma",
        "outputId": "58cc49c2-749b-4116-ef19-cb7a87427171"
      },
      "source": [
        "epochs = 500\n",
        "lr = 5e-1\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5946.3140\n",
            "Epoch [40], val_loss: 5945.2104\n",
            "Epoch [60], val_loss: 5938.5830\n",
            "Epoch [80], val_loss: 5953.7910\n",
            "Epoch [100], val_loss: 5937.7793\n",
            "Epoch [120], val_loss: 5952.2661\n",
            "Epoch [140], val_loss: 5922.8525\n",
            "Epoch [160], val_loss: 5920.1919\n",
            "Epoch [180], val_loss: 5954.3433\n",
            "Epoch [200], val_loss: 5934.0439\n",
            "Epoch [220], val_loss: 5909.8218\n",
            "Epoch [240], val_loss: 5913.5942\n",
            "Epoch [260], val_loss: 5902.6831\n",
            "Epoch [280], val_loss: 5927.3994\n",
            "Epoch [300], val_loss: 5897.5205\n",
            "Epoch [320], val_loss: 5889.8384\n",
            "Epoch [340], val_loss: 5890.1582\n",
            "Epoch [360], val_loss: 5884.9971\n",
            "Epoch [380], val_loss: 5883.9312\n",
            "Epoch [400], val_loss: 5882.8271\n",
            "Epoch [420], val_loss: 5888.9614\n",
            "Epoch [440], val_loss: 5908.4971\n",
            "Epoch [460], val_loss: 5865.1025\n",
            "Epoch [480], val_loss: 5860.0366\n",
            "Epoch [500], val_loss: 5856.4717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJc3gAZNzAma",
        "outputId": "65deaa08-4f70-4ca1-f386-9e886e93fc26"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 5e-1\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5872.4785\n",
            "Epoch [40], val_loss: 5851.9141\n",
            "Epoch [60], val_loss: 5847.5967\n",
            "Epoch [80], val_loss: 5852.0317\n",
            "Epoch [100], val_loss: 5849.3389\n",
            "Epoch [120], val_loss: 5878.2246\n",
            "Epoch [140], val_loss: 5837.0522\n",
            "Epoch [160], val_loss: 5827.5444\n",
            "Epoch [180], val_loss: 5829.2124\n",
            "Epoch [200], val_loss: 5835.4033\n",
            "Epoch [220], val_loss: 5821.9937\n",
            "Epoch [240], val_loss: 5818.8950\n",
            "Epoch [260], val_loss: 5852.5991\n",
            "Epoch [280], val_loss: 5811.5044\n",
            "Epoch [300], val_loss: 5803.9502\n",
            "Epoch [320], val_loss: 5798.8081\n",
            "Epoch [340], val_loss: 5797.1484\n",
            "Epoch [360], val_loss: 5805.6616\n",
            "Epoch [380], val_loss: 5808.1182\n",
            "Epoch [400], val_loss: 5785.2427\n",
            "Epoch [420], val_loss: 5787.1035\n",
            "Epoch [440], val_loss: 5801.2661\n",
            "Epoch [460], val_loss: 5774.5415\n",
            "Epoch [480], val_loss: 5793.1401\n",
            "Epoch [500], val_loss: 5793.8335\n",
            "Epoch [520], val_loss: 5765.9375\n",
            "Epoch [540], val_loss: 5763.1626\n",
            "Epoch [560], val_loss: 5757.2134\n",
            "Epoch [580], val_loss: 5758.9297\n",
            "Epoch [600], val_loss: 5758.3896\n",
            "Epoch [620], val_loss: 5746.4937\n",
            "Epoch [640], val_loss: 5748.4839\n",
            "Epoch [660], val_loss: 5748.9404\n",
            "Epoch [680], val_loss: 5741.7876\n",
            "Epoch [700], val_loss: 5733.0708\n",
            "Epoch [720], val_loss: 5734.1851\n",
            "Epoch [740], val_loss: 5737.7944\n",
            "Epoch [760], val_loss: 5732.0908\n",
            "Epoch [780], val_loss: 5728.9141\n",
            "Epoch [800], val_loss: 5733.0498\n",
            "Epoch [820], val_loss: 5710.2881\n",
            "Epoch [840], val_loss: 5714.4619\n",
            "Epoch [860], val_loss: 5703.2720\n",
            "Epoch [880], val_loss: 5699.3218\n",
            "Epoch [900], val_loss: 5736.1880\n",
            "Epoch [920], val_loss: 5692.9556\n",
            "Epoch [940], val_loss: 5730.6128\n",
            "Epoch [960], val_loss: 5694.6118\n",
            "Epoch [980], val_loss: 5691.4624\n",
            "Epoch [1000], val_loss: 5683.7676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCDlcriGzAma",
        "outputId": "09e0bc07-4bfc-48aa-ceda-29d2febcd1d6"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 2e-1\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5676.9888\n",
            "Epoch [40], val_loss: 5683.3267\n",
            "Epoch [60], val_loss: 5675.7676\n",
            "Epoch [80], val_loss: 5673.4443\n",
            "Epoch [100], val_loss: 5672.1006\n",
            "Epoch [120], val_loss: 5670.0117\n",
            "Epoch [140], val_loss: 5668.9683\n",
            "Epoch [160], val_loss: 5669.0112\n",
            "Epoch [180], val_loss: 5669.4038\n",
            "Epoch [200], val_loss: 5664.4473\n",
            "Epoch [220], val_loss: 5666.1489\n",
            "Epoch [240], val_loss: 5663.9722\n",
            "Epoch [260], val_loss: 5662.6626\n",
            "Epoch [280], val_loss: 5663.9976\n",
            "Epoch [300], val_loss: 5662.4526\n",
            "Epoch [320], val_loss: 5657.5283\n",
            "Epoch [340], val_loss: 5657.7236\n",
            "Epoch [360], val_loss: 5655.4346\n",
            "Epoch [380], val_loss: 5654.4390\n",
            "Epoch [400], val_loss: 5652.0366\n",
            "Epoch [420], val_loss: 5649.1846\n",
            "Epoch [440], val_loss: 5649.1221\n",
            "Epoch [460], val_loss: 5646.5796\n",
            "Epoch [480], val_loss: 5645.0107\n",
            "Epoch [500], val_loss: 5645.5771\n",
            "Epoch [520], val_loss: 5643.1675\n",
            "Epoch [540], val_loss: 5640.9414\n",
            "Epoch [560], val_loss: 5642.3252\n",
            "Epoch [580], val_loss: 5638.0947\n",
            "Epoch [600], val_loss: 5640.4346\n",
            "Epoch [620], val_loss: 5635.4785\n",
            "Epoch [640], val_loss: 5644.1714\n",
            "Epoch [660], val_loss: 5632.6367\n",
            "Epoch [680], val_loss: 5632.6606\n",
            "Epoch [700], val_loss: 5629.7432\n",
            "Epoch [720], val_loss: 5635.7720\n",
            "Epoch [740], val_loss: 5627.7676\n",
            "Epoch [760], val_loss: 5626.0381\n",
            "Epoch [780], val_loss: 5626.0439\n",
            "Epoch [800], val_loss: 5626.7070\n",
            "Epoch [820], val_loss: 5625.2236\n",
            "Epoch [840], val_loss: 5622.7949\n",
            "Epoch [860], val_loss: 5620.3613\n",
            "Epoch [880], val_loss: 5617.4102\n",
            "Epoch [900], val_loss: 5616.4663\n",
            "Epoch [920], val_loss: 5617.4341\n",
            "Epoch [940], val_loss: 5615.2046\n",
            "Epoch [960], val_loss: 5613.0679\n",
            "Epoch [980], val_loss: 5613.7266\n",
            "Epoch [1000], val_loss: 5610.4990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGA-bdrpzAma",
        "outputId": "00b85cda-7075-4946-b964-001dfc50f3e5"
      },
      "source": [
        "epochs = 5000\n",
        "lr = 1e-1\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5591.8652\n",
            "Epoch [40], val_loss: 5590.4897\n",
            "Epoch [60], val_loss: 5589.7314\n",
            "Epoch [80], val_loss: 5589.4492\n",
            "Epoch [100], val_loss: 5588.7500\n",
            "Epoch [120], val_loss: 5587.7422\n",
            "Epoch [140], val_loss: 5588.3467\n",
            "Epoch [160], val_loss: 5586.7183\n",
            "Epoch [180], val_loss: 5585.6260\n",
            "Epoch [200], val_loss: 5584.9683\n",
            "Epoch [220], val_loss: 5584.4590\n",
            "Epoch [240], val_loss: 5583.9844\n",
            "Epoch [260], val_loss: 5582.7432\n",
            "Epoch [280], val_loss: 5582.0469\n",
            "Epoch [300], val_loss: 5581.2935\n",
            "Epoch [320], val_loss: 5580.6318\n",
            "Epoch [340], val_loss: 5580.6519\n",
            "Epoch [360], val_loss: 5579.2446\n",
            "Epoch [380], val_loss: 5578.9751\n",
            "Epoch [400], val_loss: 5578.8472\n",
            "Epoch [420], val_loss: 5577.5420\n",
            "Epoch [440], val_loss: 5576.7329\n",
            "Epoch [460], val_loss: 5576.2954\n",
            "Epoch [480], val_loss: 5575.9116\n",
            "Epoch [500], val_loss: 5574.4863\n",
            "Epoch [520], val_loss: 5574.1924\n",
            "Epoch [540], val_loss: 5573.3027\n",
            "Epoch [560], val_loss: 5572.8062\n",
            "Epoch [580], val_loss: 5571.8911\n",
            "Epoch [600], val_loss: 5572.1719\n",
            "Epoch [620], val_loss: 5570.7349\n",
            "Epoch [640], val_loss: 5570.5391\n",
            "Epoch [660], val_loss: 5568.8584\n",
            "Epoch [680], val_loss: 5568.9058\n",
            "Epoch [700], val_loss: 5568.5181\n",
            "Epoch [720], val_loss: 5567.7778\n",
            "Epoch [740], val_loss: 5567.4326\n",
            "Epoch [760], val_loss: 5565.4048\n",
            "Epoch [780], val_loss: 5565.2969\n",
            "Epoch [800], val_loss: 5565.2109\n",
            "Epoch [820], val_loss: 5563.3652\n",
            "Epoch [840], val_loss: 5563.1060\n",
            "Epoch [860], val_loss: 5563.0625\n",
            "Epoch [880], val_loss: 5561.5039\n",
            "Epoch [900], val_loss: 5561.0625\n",
            "Epoch [920], val_loss: 5560.0146\n",
            "Epoch [940], val_loss: 5559.4673\n",
            "Epoch [960], val_loss: 5558.5571\n",
            "Epoch [980], val_loss: 5559.0356\n",
            "Epoch [1000], val_loss: 5558.5220\n",
            "Epoch [1020], val_loss: 5557.2632\n",
            "Epoch [1040], val_loss: 5555.7412\n",
            "Epoch [1060], val_loss: 5555.7720\n",
            "Epoch [1080], val_loss: 5555.2539\n",
            "Epoch [1100], val_loss: 5555.1729\n",
            "Epoch [1120], val_loss: 5553.4414\n",
            "Epoch [1140], val_loss: 5552.7607\n",
            "Epoch [1160], val_loss: 5551.5762\n",
            "Epoch [1180], val_loss: 5550.9121\n",
            "Epoch [1200], val_loss: 5550.2178\n",
            "Epoch [1220], val_loss: 5549.5088\n",
            "Epoch [1240], val_loss: 5548.9565\n",
            "Epoch [1260], val_loss: 5548.8481\n",
            "Epoch [1280], val_loss: 5547.4824\n",
            "Epoch [1300], val_loss: 5546.8291\n",
            "Epoch [1320], val_loss: 5547.2334\n",
            "Epoch [1340], val_loss: 5546.9067\n",
            "Epoch [1360], val_loss: 5545.4536\n",
            "Epoch [1380], val_loss: 5544.5718\n",
            "Epoch [1400], val_loss: 5544.1831\n",
            "Epoch [1420], val_loss: 5542.6958\n",
            "Epoch [1440], val_loss: 5542.2407\n",
            "Epoch [1460], val_loss: 5541.2866\n",
            "Epoch [1480], val_loss: 5541.0737\n",
            "Epoch [1500], val_loss: 5540.8394\n",
            "Epoch [1520], val_loss: 5539.1748\n",
            "Epoch [1540], val_loss: 5538.7632\n",
            "Epoch [1560], val_loss: 5538.8354\n",
            "Epoch [1580], val_loss: 5537.7466\n",
            "Epoch [1600], val_loss: 5537.0884\n",
            "Epoch [1620], val_loss: 5535.8604\n",
            "Epoch [1640], val_loss: 5535.2915\n",
            "Epoch [1660], val_loss: 5534.6416\n",
            "Epoch [1680], val_loss: 5533.8267\n",
            "Epoch [1700], val_loss: 5532.9834\n",
            "Epoch [1720], val_loss: 5532.3320\n",
            "Epoch [1740], val_loss: 5532.6055\n",
            "Epoch [1760], val_loss: 5531.1221\n",
            "Epoch [1780], val_loss: 5531.2153\n",
            "Epoch [1800], val_loss: 5530.1230\n",
            "Epoch [1820], val_loss: 5529.1323\n",
            "Epoch [1840], val_loss: 5528.4727\n",
            "Epoch [1860], val_loss: 5527.4487\n",
            "Epoch [1880], val_loss: 5527.1929\n",
            "Epoch [1900], val_loss: 5526.9043\n",
            "Epoch [1920], val_loss: 5525.5933\n",
            "Epoch [1940], val_loss: 5524.7485\n",
            "Epoch [1960], val_loss: 5524.0928\n",
            "Epoch [1980], val_loss: 5523.5425\n",
            "Epoch [2000], val_loss: 5522.7437\n",
            "Epoch [2020], val_loss: 5523.9312\n",
            "Epoch [2040], val_loss: 5521.2832\n",
            "Epoch [2060], val_loss: 5520.6362\n",
            "Epoch [2080], val_loss: 5520.0532\n",
            "Epoch [2100], val_loss: 5519.2485\n",
            "Epoch [2120], val_loss: 5518.7666\n",
            "Epoch [2140], val_loss: 5518.8467\n",
            "Epoch [2160], val_loss: 5518.5840\n",
            "Epoch [2180], val_loss: 5516.5273\n",
            "Epoch [2200], val_loss: 5515.8301\n",
            "Epoch [2220], val_loss: 5515.0493\n",
            "Epoch [2240], val_loss: 5514.5723\n",
            "Epoch [2260], val_loss: 5513.7432\n",
            "Epoch [2280], val_loss: 5514.2915\n",
            "Epoch [2300], val_loss: 5512.3994\n",
            "Epoch [2320], val_loss: 5511.7622\n",
            "Epoch [2340], val_loss: 5511.0122\n",
            "Epoch [2360], val_loss: 5510.2905\n",
            "Epoch [2380], val_loss: 5509.5571\n",
            "Epoch [2400], val_loss: 5512.3989\n",
            "Epoch [2420], val_loss: 5509.5264\n",
            "Epoch [2440], val_loss: 5509.3921\n",
            "Epoch [2460], val_loss: 5507.8813\n",
            "Epoch [2480], val_loss: 5507.7290\n",
            "Epoch [2500], val_loss: 5507.6558\n",
            "Epoch [2520], val_loss: 5506.1528\n",
            "Epoch [2540], val_loss: 5504.0835\n",
            "Epoch [2560], val_loss: 5503.3765\n",
            "Epoch [2580], val_loss: 5502.9346\n",
            "Epoch [2600], val_loss: 5502.0562\n",
            "Epoch [2620], val_loss: 5501.3330\n",
            "Epoch [2640], val_loss: 5501.8774\n",
            "Epoch [2660], val_loss: 5504.8452\n",
            "Epoch [2680], val_loss: 5499.2295\n",
            "Epoch [2700], val_loss: 5498.8921\n",
            "Epoch [2720], val_loss: 5497.8594\n",
            "Epoch [2740], val_loss: 5498.2466\n",
            "Epoch [2760], val_loss: 5496.5894\n",
            "Epoch [2780], val_loss: 5495.7861\n",
            "Epoch [2800], val_loss: 5495.1396\n",
            "Epoch [2820], val_loss: 5494.4956\n",
            "Epoch [2840], val_loss: 5494.6138\n",
            "Epoch [2860], val_loss: 5493.0752\n",
            "Epoch [2880], val_loss: 5492.6577\n",
            "Epoch [2900], val_loss: 5491.6802\n",
            "Epoch [2920], val_loss: 5490.9946\n",
            "Epoch [2940], val_loss: 5490.4175\n",
            "Epoch [2960], val_loss: 5489.6685\n",
            "Epoch [2980], val_loss: 5489.0430\n",
            "Epoch [3000], val_loss: 5488.8818\n",
            "Epoch [3020], val_loss: 5487.5391\n",
            "Epoch [3040], val_loss: 5487.7749\n",
            "Epoch [3060], val_loss: 5487.7490\n",
            "Epoch [3080], val_loss: 5485.4814\n",
            "Epoch [3100], val_loss: 5484.8755\n",
            "Epoch [3120], val_loss: 5484.4570\n",
            "Epoch [3140], val_loss: 5483.8354\n",
            "Epoch [3160], val_loss: 5482.8613\n",
            "Epoch [3180], val_loss: 5482.5122\n",
            "Epoch [3200], val_loss: 5481.5439\n",
            "Epoch [3220], val_loss: 5480.9404\n",
            "Epoch [3240], val_loss: 5483.0303\n",
            "Epoch [3260], val_loss: 5481.1362\n",
            "Epoch [3280], val_loss: 5480.4888\n",
            "Epoch [3300], val_loss: 5479.9146\n",
            "Epoch [3320], val_loss: 5478.2192\n",
            "Epoch [3340], val_loss: 5476.8403\n",
            "Epoch [3360], val_loss: 5475.8252\n",
            "Epoch [3380], val_loss: 5476.5942\n",
            "Epoch [3400], val_loss: 5474.6118\n",
            "Epoch [3420], val_loss: 5474.8857\n",
            "Epoch [3440], val_loss: 5473.2500\n",
            "Epoch [3460], val_loss: 5472.5366\n",
            "Epoch [3480], val_loss: 5471.7471\n",
            "Epoch [3500], val_loss: 5474.4087\n",
            "Epoch [3520], val_loss: 5472.8179\n",
            "Epoch [3540], val_loss: 5469.7207\n",
            "Epoch [3560], val_loss: 5469.0435\n",
            "Epoch [3580], val_loss: 5468.8921\n",
            "Epoch [3600], val_loss: 5467.7505\n",
            "Epoch [3620], val_loss: 5467.5186\n",
            "Epoch [3640], val_loss: 5466.3345\n",
            "Epoch [3660], val_loss: 5466.5063\n",
            "Epoch [3680], val_loss: 5465.0962\n",
            "Epoch [3700], val_loss: 5464.8770\n",
            "Epoch [3720], val_loss: 5463.5532\n",
            "Epoch [3740], val_loss: 5462.9136\n",
            "Epoch [3760], val_loss: 5462.4399\n",
            "Epoch [3780], val_loss: 5463.1787\n",
            "Epoch [3800], val_loss: 5460.9243\n",
            "Epoch [3820], val_loss: 5460.5605\n",
            "Epoch [3840], val_loss: 5461.5400\n",
            "Epoch [3860], val_loss: 5460.4473\n",
            "Epoch [3880], val_loss: 5458.9067\n",
            "Epoch [3900], val_loss: 5457.4038\n",
            "Epoch [3920], val_loss: 5457.4194\n",
            "Epoch [3940], val_loss: 5456.2827\n",
            "Epoch [3960], val_loss: 5456.2764\n",
            "Epoch [3980], val_loss: 5456.3770\n",
            "Epoch [4000], val_loss: 5456.6021\n",
            "Epoch [4020], val_loss: 5453.3887\n",
            "Epoch [4040], val_loss: 5453.1733\n",
            "Epoch [4060], val_loss: 5453.6104\n",
            "Epoch [4080], val_loss: 5451.4180\n",
            "Epoch [4100], val_loss: 5452.0298\n",
            "Epoch [4120], val_loss: 5450.4580\n",
            "Epoch [4140], val_loss: 5449.5283\n",
            "Epoch [4160], val_loss: 5449.6235\n",
            "Epoch [4180], val_loss: 5447.9673\n",
            "Epoch [4200], val_loss: 5448.1646\n",
            "Epoch [4220], val_loss: 5446.9756\n",
            "Epoch [4240], val_loss: 5445.6792\n",
            "Epoch [4260], val_loss: 5445.0200\n",
            "Epoch [4280], val_loss: 5444.2563\n",
            "Epoch [4300], val_loss: 5444.5435\n",
            "Epoch [4320], val_loss: 5443.0249\n",
            "Epoch [4340], val_loss: 5443.9316\n",
            "Epoch [4360], val_loss: 5442.3315\n",
            "Epoch [4380], val_loss: 5441.5083\n",
            "Epoch [4400], val_loss: 5440.2373\n",
            "Epoch [4420], val_loss: 5439.5166\n",
            "Epoch [4440], val_loss: 5439.5815\n",
            "Epoch [4460], val_loss: 5438.2197\n",
            "Epoch [4480], val_loss: 5438.7563\n",
            "Epoch [4500], val_loss: 5437.5615\n",
            "Epoch [4520], val_loss: 5436.3442\n",
            "Epoch [4540], val_loss: 5435.5342\n",
            "Epoch [4560], val_loss: 5436.6235\n",
            "Epoch [4580], val_loss: 5434.8701\n",
            "Epoch [4600], val_loss: 5434.3101\n",
            "Epoch [4620], val_loss: 5432.8975\n",
            "Epoch [4640], val_loss: 5433.1392\n",
            "Epoch [4660], val_loss: 5431.5864\n",
            "Epoch [4680], val_loss: 5431.0322\n",
            "Epoch [4700], val_loss: 5430.3711\n",
            "Epoch [4720], val_loss: 5430.0493\n",
            "Epoch [4740], val_loss: 5429.3018\n",
            "Epoch [4760], val_loss: 5428.1206\n",
            "Epoch [4780], val_loss: 5427.4683\n",
            "Epoch [4800], val_loss: 5426.8608\n",
            "Epoch [4820], val_loss: 5425.9678\n",
            "Epoch [4840], val_loss: 5425.4639\n",
            "Epoch [4860], val_loss: 5424.8965\n",
            "Epoch [4880], val_loss: 5424.0698\n",
            "Epoch [4900], val_loss: 5423.5708\n",
            "Epoch [4920], val_loss: 5423.8989\n",
            "Epoch [4940], val_loss: 5422.7520\n",
            "Epoch [4960], val_loss: 5421.1606\n",
            "Epoch [4980], val_loss: 5420.6831\n",
            "Epoch [5000], val_loss: 5419.9468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEI_1F8DOjLg",
        "outputId": "29d8c9f3-3712-4560-8275-6d868239f223"
      },
      "source": [
        "epochs = 5000\n",
        "lr = 1e-1\n",
        "history6 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5420.3628\n",
            "Epoch [40], val_loss: 5419.2979\n",
            "Epoch [60], val_loss: 5418.1260\n",
            "Epoch [80], val_loss: 5417.7817\n",
            "Epoch [100], val_loss: 5416.7739\n",
            "Epoch [120], val_loss: 5416.9185\n",
            "Epoch [140], val_loss: 5414.9712\n",
            "Epoch [160], val_loss: 5414.3643\n",
            "Epoch [180], val_loss: 5413.9771\n",
            "Epoch [200], val_loss: 5413.8076\n",
            "Epoch [220], val_loss: 5412.5186\n",
            "Epoch [240], val_loss: 5412.9238\n",
            "Epoch [260], val_loss: 5410.9629\n",
            "Epoch [280], val_loss: 5411.1831\n",
            "Epoch [300], val_loss: 5410.9209\n",
            "Epoch [320], val_loss: 5410.2036\n",
            "Epoch [340], val_loss: 5408.2661\n",
            "Epoch [360], val_loss: 5408.8760\n",
            "Epoch [380], val_loss: 5407.9199\n",
            "Epoch [400], val_loss: 5406.6206\n",
            "Epoch [420], val_loss: 5405.5200\n",
            "Epoch [440], val_loss: 5405.1279\n",
            "Epoch [460], val_loss: 5404.1250\n",
            "Epoch [480], val_loss: 5403.3125\n",
            "Epoch [500], val_loss: 5406.1040\n",
            "Epoch [520], val_loss: 5403.4639\n",
            "Epoch [540], val_loss: 5401.4023\n",
            "Epoch [560], val_loss: 5400.9126\n",
            "Epoch [580], val_loss: 5401.1143\n",
            "Epoch [600], val_loss: 5399.5093\n",
            "Epoch [620], val_loss: 5402.3228\n",
            "Epoch [640], val_loss: 5397.9023\n",
            "Epoch [660], val_loss: 5398.7896\n",
            "Epoch [680], val_loss: 5396.4907\n",
            "Epoch [700], val_loss: 5398.3994\n",
            "Epoch [720], val_loss: 5395.1411\n",
            "Epoch [740], val_loss: 5394.4976\n",
            "Epoch [760], val_loss: 5396.0137\n",
            "Epoch [780], val_loss: 5394.9692\n",
            "Epoch [800], val_loss: 5392.8770\n",
            "Epoch [820], val_loss: 5392.0791\n",
            "Epoch [840], val_loss: 5391.6880\n",
            "Epoch [860], val_loss: 5390.4800\n",
            "Epoch [880], val_loss: 5391.0757\n",
            "Epoch [900], val_loss: 5389.8628\n",
            "Epoch [920], val_loss: 5388.5796\n",
            "Epoch [940], val_loss: 5388.4702\n",
            "Epoch [960], val_loss: 5387.6763\n",
            "Epoch [980], val_loss: 5386.3159\n",
            "Epoch [1000], val_loss: 5386.4712\n",
            "Epoch [1020], val_loss: 5385.7271\n",
            "Epoch [1040], val_loss: 5384.5679\n",
            "Epoch [1060], val_loss: 5383.6157\n",
            "Epoch [1080], val_loss: 5385.8345\n",
            "Epoch [1100], val_loss: 5382.0737\n",
            "Epoch [1120], val_loss: 5381.5508\n",
            "Epoch [1140], val_loss: 5381.1504\n",
            "Epoch [1160], val_loss: 5380.2593\n",
            "Epoch [1180], val_loss: 5379.6489\n",
            "Epoch [1200], val_loss: 5378.7163\n",
            "Epoch [1220], val_loss: 5378.2109\n",
            "Epoch [1240], val_loss: 5377.4473\n",
            "Epoch [1260], val_loss: 5376.8091\n",
            "Epoch [1280], val_loss: 5376.1855\n",
            "Epoch [1300], val_loss: 5375.4937\n",
            "Epoch [1320], val_loss: 5375.2114\n",
            "Epoch [1340], val_loss: 5376.5269\n",
            "Epoch [1360], val_loss: 5374.6968\n",
            "Epoch [1380], val_loss: 5372.9067\n",
            "Epoch [1400], val_loss: 5374.9966\n",
            "Epoch [1420], val_loss: 5373.7207\n",
            "Epoch [1440], val_loss: 5371.0176\n",
            "Epoch [1460], val_loss: 5370.0605\n",
            "Epoch [1480], val_loss: 5369.9277\n",
            "Epoch [1500], val_loss: 5372.1782\n",
            "Epoch [1520], val_loss: 5368.4692\n",
            "Epoch [1540], val_loss: 5367.8003\n",
            "Epoch [1560], val_loss: 5369.0566\n",
            "Epoch [1580], val_loss: 5366.0835\n",
            "Epoch [1600], val_loss: 5365.1738\n",
            "Epoch [1620], val_loss: 5364.9771\n",
            "Epoch [1640], val_loss: 5364.0010\n",
            "Epoch [1660], val_loss: 5363.0854\n",
            "Epoch [1680], val_loss: 5364.4390\n",
            "Epoch [1700], val_loss: 5361.6509\n",
            "Epoch [1720], val_loss: 5361.0854\n",
            "Epoch [1740], val_loss: 5360.5972\n",
            "Epoch [1760], val_loss: 5361.1421\n",
            "Epoch [1780], val_loss: 5359.6938\n",
            "Epoch [1800], val_loss: 5360.1606\n",
            "Epoch [1820], val_loss: 5357.5415\n",
            "Epoch [1840], val_loss: 5361.6177\n",
            "Epoch [1860], val_loss: 5356.3594\n",
            "Epoch [1880], val_loss: 5358.8447\n",
            "Epoch [1900], val_loss: 5355.3452\n",
            "Epoch [1920], val_loss: 5354.3096\n",
            "Epoch [1940], val_loss: 5354.7808\n",
            "Epoch [1960], val_loss: 5354.4873\n",
            "Epoch [1980], val_loss: 5352.0078\n",
            "Epoch [2000], val_loss: 5351.7568\n",
            "Epoch [2020], val_loss: 5351.5620\n",
            "Epoch [2040], val_loss: 5350.5469\n",
            "Epoch [2060], val_loss: 5349.4507\n",
            "Epoch [2080], val_loss: 5348.7212\n",
            "Epoch [2100], val_loss: 5348.1782\n",
            "Epoch [2120], val_loss: 5350.0317\n",
            "Epoch [2140], val_loss: 5350.7153\n",
            "Epoch [2160], val_loss: 5346.0200\n",
            "Epoch [2180], val_loss: 5345.5396\n",
            "Epoch [2200], val_loss: 5346.4004\n",
            "Epoch [2220], val_loss: 5344.2114\n",
            "Epoch [2240], val_loss: 5343.5386\n",
            "Epoch [2260], val_loss: 5343.2168\n",
            "Epoch [2280], val_loss: 5342.2925\n",
            "Epoch [2300], val_loss: 5341.9790\n",
            "Epoch [2320], val_loss: 5346.0796\n",
            "Epoch [2340], val_loss: 5340.0200\n",
            "Epoch [2360], val_loss: 5339.2598\n",
            "Epoch [2380], val_loss: 5339.7363\n",
            "Epoch [2400], val_loss: 5338.3032\n",
            "Epoch [2420], val_loss: 5337.7783\n",
            "Epoch [2440], val_loss: 5336.4585\n",
            "Epoch [2460], val_loss: 5336.4604\n",
            "Epoch [2480], val_loss: 5336.6748\n",
            "Epoch [2500], val_loss: 5335.2896\n",
            "Epoch [2520], val_loss: 5333.9487\n",
            "Epoch [2540], val_loss: 5333.3740\n",
            "Epoch [2560], val_loss: 5332.4419\n",
            "Epoch [2580], val_loss: 5331.9233\n",
            "Epoch [2600], val_loss: 5331.1084\n",
            "Epoch [2620], val_loss: 5330.4785\n",
            "Epoch [2640], val_loss: 5329.8687\n",
            "Epoch [2660], val_loss: 5329.4404\n",
            "Epoch [2680], val_loss: 5328.3442\n",
            "Epoch [2700], val_loss: 5327.9487\n",
            "Epoch [2720], val_loss: 5327.4351\n",
            "Epoch [2740], val_loss: 5326.9834\n",
            "Epoch [2760], val_loss: 5325.6147\n",
            "Epoch [2780], val_loss: 5325.6543\n",
            "Epoch [2800], val_loss: 5324.1919\n",
            "Epoch [2820], val_loss: 5324.3735\n",
            "Epoch [2840], val_loss: 5324.1416\n",
            "Epoch [2860], val_loss: 5323.3296\n",
            "Epoch [2880], val_loss: 5321.9316\n",
            "Epoch [2900], val_loss: 5322.7920\n",
            "Epoch [2920], val_loss: 5323.3428\n",
            "Epoch [2940], val_loss: 5320.8345\n",
            "Epoch [2960], val_loss: 5318.8013\n",
            "Epoch [2980], val_loss: 5320.5732\n",
            "Epoch [3000], val_loss: 5318.9595\n",
            "Epoch [3020], val_loss: 5318.7778\n",
            "Epoch [3040], val_loss: 5317.3613\n",
            "Epoch [3060], val_loss: 5316.1045\n",
            "Epoch [3080], val_loss: 5315.9175\n",
            "Epoch [3100], val_loss: 5315.4888\n",
            "Epoch [3120], val_loss: 5313.4639\n",
            "Epoch [3140], val_loss: 5312.6904\n",
            "Epoch [3160], val_loss: 5312.8906\n",
            "Epoch [3180], val_loss: 5313.2236\n",
            "Epoch [3200], val_loss: 5310.9478\n",
            "Epoch [3220], val_loss: 5310.7905\n",
            "Epoch [3240], val_loss: 5310.6768\n",
            "Epoch [3260], val_loss: 5308.6880\n",
            "Epoch [3280], val_loss: 5308.3091\n",
            "Epoch [3300], val_loss: 5307.2104\n",
            "Epoch [3320], val_loss: 5308.1260\n",
            "Epoch [3340], val_loss: 5305.8911\n",
            "Epoch [3360], val_loss: 5305.2275\n",
            "Epoch [3380], val_loss: 5305.9209\n",
            "Epoch [3400], val_loss: 5305.3447\n",
            "Epoch [3420], val_loss: 5303.5029\n",
            "Epoch [3440], val_loss: 5306.2119\n",
            "Epoch [3460], val_loss: 5303.8267\n",
            "Epoch [3480], val_loss: 5301.6304\n",
            "Epoch [3500], val_loss: 5300.4409\n",
            "Epoch [3520], val_loss: 5301.5166\n",
            "Epoch [3540], val_loss: 5299.1094\n",
            "Epoch [3560], val_loss: 5298.6470\n",
            "Epoch [3580], val_loss: 5299.1875\n",
            "Epoch [3600], val_loss: 5298.2461\n",
            "Epoch [3620], val_loss: 5296.8511\n",
            "Epoch [3640], val_loss: 5295.7612\n",
            "Epoch [3660], val_loss: 5295.8164\n",
            "Epoch [3680], val_loss: 5296.4229\n",
            "Epoch [3700], val_loss: 5294.2295\n",
            "Epoch [3720], val_loss: 5293.0479\n",
            "Epoch [3740], val_loss: 5294.9053\n",
            "Epoch [3760], val_loss: 5291.7178\n",
            "Epoch [3780], val_loss: 5291.5005\n",
            "Epoch [3800], val_loss: 5290.7734\n",
            "Epoch [3820], val_loss: 5290.4971\n",
            "Epoch [3840], val_loss: 5289.3984\n",
            "Epoch [3860], val_loss: 5288.7969\n",
            "Epoch [3880], val_loss: 5287.6758\n",
            "Epoch [3900], val_loss: 5287.1299\n",
            "Epoch [3920], val_loss: 5286.4648\n",
            "Epoch [3940], val_loss: 5285.6245\n",
            "Epoch [3960], val_loss: 5287.2598\n",
            "Epoch [3980], val_loss: 5288.4844\n",
            "Epoch [4000], val_loss: 5284.9199\n",
            "Epoch [4020], val_loss: 5283.1582\n",
            "Epoch [4040], val_loss: 5282.2451\n",
            "Epoch [4060], val_loss: 5281.6626\n",
            "Epoch [4080], val_loss: 5281.6353\n",
            "Epoch [4100], val_loss: 5281.2896\n",
            "Epoch [4120], val_loss: 5279.5830\n",
            "Epoch [4140], val_loss: 5279.1694\n",
            "Epoch [4160], val_loss: 5278.3623\n",
            "Epoch [4180], val_loss: 5277.7495\n",
            "Epoch [4200], val_loss: 5278.5317\n",
            "Epoch [4220], val_loss: 5276.7744\n",
            "Epoch [4240], val_loss: 5275.9312\n",
            "Epoch [4260], val_loss: 5276.1772\n",
            "Epoch [4280], val_loss: 5274.8047\n",
            "Epoch [4300], val_loss: 5274.6265\n",
            "Epoch [4320], val_loss: 5275.4399\n",
            "Epoch [4340], val_loss: 5272.4141\n",
            "Epoch [4360], val_loss: 5273.7271\n",
            "Epoch [4380], val_loss: 5271.3892\n",
            "Epoch [4400], val_loss: 5270.3301\n",
            "Epoch [4420], val_loss: 5269.9683\n",
            "Epoch [4440], val_loss: 5269.5923\n",
            "Epoch [4460], val_loss: 5271.6958\n",
            "Epoch [4480], val_loss: 5267.4126\n",
            "Epoch [4500], val_loss: 5267.3892\n",
            "Epoch [4520], val_loss: 5266.2607\n",
            "Epoch [4540], val_loss: 5266.5049\n",
            "Epoch [4560], val_loss: 5266.5454\n",
            "Epoch [4580], val_loss: 5264.8345\n",
            "Epoch [4600], val_loss: 5263.4097\n",
            "Epoch [4620], val_loss: 5264.1270\n",
            "Epoch [4640], val_loss: 5262.3594\n",
            "Epoch [4660], val_loss: 5261.6094\n",
            "Epoch [4680], val_loss: 5261.0942\n",
            "Epoch [4700], val_loss: 5262.4014\n",
            "Epoch [4720], val_loss: 5260.2344\n",
            "Epoch [4740], val_loss: 5261.2095\n",
            "Epoch [4760], val_loss: 5259.4526\n",
            "Epoch [4780], val_loss: 5257.6602\n",
            "Epoch [4800], val_loss: 5257.0747\n",
            "Epoch [4820], val_loss: 5256.3379\n",
            "Epoch [4840], val_loss: 5258.1650\n",
            "Epoch [4860], val_loss: 5254.9492\n",
            "Epoch [4880], val_loss: 5254.6094\n",
            "Epoch [4900], val_loss: 5253.9644\n",
            "Epoch [4920], val_loss: 5252.7632\n",
            "Epoch [4940], val_loss: 5251.9209\n",
            "Epoch [4960], val_loss: 5252.2749\n",
            "Epoch [4980], val_loss: 5250.6689\n",
            "Epoch [5000], val_loss: 5252.1152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfi9CaDqPCSn",
        "outputId": "563820c9-1aba-411d-f8e7-4e18092e62cb"
      },
      "source": [
        "epochs = 5000\n",
        "lr = 1e-2\n",
        "history7 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5250.3418\n",
            "Epoch [40], val_loss: 5250.2734\n",
            "Epoch [60], val_loss: 5250.1948\n",
            "Epoch [80], val_loss: 5250.0156\n",
            "Epoch [100], val_loss: 5249.9673\n",
            "Epoch [120], val_loss: 5249.9292\n",
            "Epoch [140], val_loss: 5249.8081\n",
            "Epoch [160], val_loss: 5249.7207\n",
            "Epoch [180], val_loss: 5249.7358\n",
            "Epoch [200], val_loss: 5249.5371\n",
            "Epoch [220], val_loss: 5249.5601\n",
            "Epoch [240], val_loss: 5249.5840\n",
            "Epoch [260], val_loss: 5249.4385\n",
            "Epoch [280], val_loss: 5249.3247\n",
            "Epoch [300], val_loss: 5249.3394\n",
            "Epoch [320], val_loss: 5249.2026\n",
            "Epoch [340], val_loss: 5249.1812\n",
            "Epoch [360], val_loss: 5249.0713\n",
            "Epoch [380], val_loss: 5249.1338\n",
            "Epoch [400], val_loss: 5248.9595\n",
            "Epoch [420], val_loss: 5248.8589\n",
            "Epoch [440], val_loss: 5248.8149\n",
            "Epoch [460], val_loss: 5248.7598\n",
            "Epoch [480], val_loss: 5248.6118\n",
            "Epoch [500], val_loss: 5248.4985\n",
            "Epoch [520], val_loss: 5248.5352\n",
            "Epoch [540], val_loss: 5248.4609\n",
            "Epoch [560], val_loss: 5248.4526\n",
            "Epoch [580], val_loss: 5248.3091\n",
            "Epoch [600], val_loss: 5248.2280\n",
            "Epoch [620], val_loss: 5248.2192\n",
            "Epoch [640], val_loss: 5248.0303\n",
            "Epoch [660], val_loss: 5248.1650\n",
            "Epoch [680], val_loss: 5247.9385\n",
            "Epoch [700], val_loss: 5247.9995\n",
            "Epoch [720], val_loss: 5247.8989\n",
            "Epoch [740], val_loss: 5247.7417\n",
            "Epoch [760], val_loss: 5247.7041\n",
            "Epoch [780], val_loss: 5247.6919\n",
            "Epoch [800], val_loss: 5247.5562\n",
            "Epoch [820], val_loss: 5247.6626\n",
            "Epoch [840], val_loss: 5247.4028\n",
            "Epoch [860], val_loss: 5247.4497\n",
            "Epoch [880], val_loss: 5247.3140\n",
            "Epoch [900], val_loss: 5247.2246\n",
            "Epoch [920], val_loss: 5247.1943\n",
            "Epoch [940], val_loss: 5247.1895\n",
            "Epoch [960], val_loss: 5247.0249\n",
            "Epoch [980], val_loss: 5247.0146\n",
            "Epoch [1000], val_loss: 5246.9805\n",
            "Epoch [1020], val_loss: 5246.9014\n",
            "Epoch [1040], val_loss: 5246.8589\n",
            "Epoch [1060], val_loss: 5246.7510\n",
            "Epoch [1080], val_loss: 5246.7178\n",
            "Epoch [1100], val_loss: 5246.5742\n",
            "Epoch [1120], val_loss: 5246.6055\n",
            "Epoch [1140], val_loss: 5246.5273\n",
            "Epoch [1160], val_loss: 5246.4106\n",
            "Epoch [1180], val_loss: 5246.4004\n",
            "Epoch [1200], val_loss: 5246.3003\n",
            "Epoch [1220], val_loss: 5246.2764\n",
            "Epoch [1240], val_loss: 5246.1875\n",
            "Epoch [1260], val_loss: 5246.1025\n",
            "Epoch [1280], val_loss: 5246.0259\n",
            "Epoch [1300], val_loss: 5245.9150\n",
            "Epoch [1320], val_loss: 5245.8882\n",
            "Epoch [1340], val_loss: 5245.8179\n",
            "Epoch [1360], val_loss: 5245.7549\n",
            "Epoch [1380], val_loss: 5245.6938\n",
            "Epoch [1400], val_loss: 5245.5752\n",
            "Epoch [1420], val_loss: 5245.5571\n",
            "Epoch [1440], val_loss: 5245.5317\n",
            "Epoch [1460], val_loss: 5245.4609\n",
            "Epoch [1480], val_loss: 5245.3691\n",
            "Epoch [1500], val_loss: 5245.3086\n",
            "Epoch [1520], val_loss: 5245.1440\n",
            "Epoch [1540], val_loss: 5245.2070\n",
            "Epoch [1560], val_loss: 5244.9707\n",
            "Epoch [1580], val_loss: 5244.9683\n",
            "Epoch [1600], val_loss: 5244.9507\n",
            "Epoch [1620], val_loss: 5244.9136\n",
            "Epoch [1640], val_loss: 5244.7686\n",
            "Epoch [1660], val_loss: 5244.7646\n",
            "Epoch [1680], val_loss: 5244.6318\n",
            "Epoch [1700], val_loss: 5244.5688\n",
            "Epoch [1720], val_loss: 5244.5122\n",
            "Epoch [1740], val_loss: 5244.5186\n",
            "Epoch [1760], val_loss: 5244.4424\n",
            "Epoch [1780], val_loss: 5244.3594\n",
            "Epoch [1800], val_loss: 5244.3706\n",
            "Epoch [1820], val_loss: 5244.2529\n",
            "Epoch [1840], val_loss: 5244.0864\n",
            "Epoch [1860], val_loss: 5244.0908\n",
            "Epoch [1880], val_loss: 5244.0693\n",
            "Epoch [1900], val_loss: 5244.0322\n",
            "Epoch [1920], val_loss: 5243.9033\n",
            "Epoch [1940], val_loss: 5243.9648\n",
            "Epoch [1960], val_loss: 5243.8306\n",
            "Epoch [1980], val_loss: 5243.7622\n",
            "Epoch [2000], val_loss: 5243.6807\n",
            "Epoch [2020], val_loss: 5243.5908\n",
            "Epoch [2040], val_loss: 5243.3286\n",
            "Epoch [2060], val_loss: 5243.4302\n",
            "Epoch [2080], val_loss: 5243.3354\n",
            "Epoch [2100], val_loss: 5243.3145\n",
            "Epoch [2120], val_loss: 5243.2192\n",
            "Epoch [2140], val_loss: 5243.1177\n",
            "Epoch [2160], val_loss: 5243.0298\n",
            "Epoch [2180], val_loss: 5242.9766\n",
            "Epoch [2200], val_loss: 5242.9795\n",
            "Epoch [2220], val_loss: 5242.9614\n",
            "Epoch [2240], val_loss: 5242.7334\n",
            "Epoch [2260], val_loss: 5242.7129\n",
            "Epoch [2280], val_loss: 5242.7173\n",
            "Epoch [2300], val_loss: 5242.5850\n",
            "Epoch [2320], val_loss: 5242.4697\n",
            "Epoch [2340], val_loss: 5242.5288\n",
            "Epoch [2360], val_loss: 5242.4336\n",
            "Epoch [2380], val_loss: 5242.3218\n",
            "Epoch [2400], val_loss: 5242.2861\n",
            "Epoch [2420], val_loss: 5242.1099\n",
            "Epoch [2440], val_loss: 5242.0503\n",
            "Epoch [2460], val_loss: 5241.9619\n",
            "Epoch [2480], val_loss: 5241.9766\n",
            "Epoch [2500], val_loss: 5241.9683\n",
            "Epoch [2520], val_loss: 5241.9590\n",
            "Epoch [2540], val_loss: 5241.8110\n",
            "Epoch [2560], val_loss: 5241.7046\n",
            "Epoch [2580], val_loss: 5241.6279\n",
            "Epoch [2600], val_loss: 5241.6294\n",
            "Epoch [2620], val_loss: 5241.4927\n",
            "Epoch [2640], val_loss: 5241.4375\n",
            "Epoch [2660], val_loss: 5241.3701\n",
            "Epoch [2680], val_loss: 5241.3496\n",
            "Epoch [2700], val_loss: 5241.2109\n",
            "Epoch [2720], val_loss: 5241.0996\n",
            "Epoch [2740], val_loss: 5241.1377\n",
            "Epoch [2760], val_loss: 5241.0742\n",
            "Epoch [2780], val_loss: 5241.0142\n",
            "Epoch [2800], val_loss: 5241.0552\n",
            "Epoch [2820], val_loss: 5240.8384\n",
            "Epoch [2840], val_loss: 5240.7114\n",
            "Epoch [2860], val_loss: 5240.6367\n",
            "Epoch [2880], val_loss: 5240.7227\n",
            "Epoch [2900], val_loss: 5240.5088\n",
            "Epoch [2920], val_loss: 5240.4854\n",
            "Epoch [2940], val_loss: 5240.4482\n",
            "Epoch [2960], val_loss: 5240.5444\n",
            "Epoch [2980], val_loss: 5240.3545\n",
            "Epoch [3000], val_loss: 5240.3125\n",
            "Epoch [3020], val_loss: 5240.1533\n",
            "Epoch [3040], val_loss: 5240.1523\n",
            "Epoch [3060], val_loss: 5239.9468\n",
            "Epoch [3080], val_loss: 5240.0645\n",
            "Epoch [3100], val_loss: 5239.8867\n",
            "Epoch [3120], val_loss: 5239.8457\n",
            "Epoch [3140], val_loss: 5239.9409\n",
            "Epoch [3160], val_loss: 5239.7051\n",
            "Epoch [3180], val_loss: 5239.7314\n",
            "Epoch [3200], val_loss: 5239.6450\n",
            "Epoch [3220], val_loss: 5239.5327\n",
            "Epoch [3240], val_loss: 5239.4243\n",
            "Epoch [3260], val_loss: 5239.4263\n",
            "Epoch [3280], val_loss: 5239.2754\n",
            "Epoch [3300], val_loss: 5239.2754\n",
            "Epoch [3320], val_loss: 5239.1846\n",
            "Epoch [3340], val_loss: 5239.1450\n",
            "Epoch [3360], val_loss: 5238.9883\n",
            "Epoch [3380], val_loss: 5238.9995\n",
            "Epoch [3400], val_loss: 5238.9453\n",
            "Epoch [3420], val_loss: 5238.9053\n",
            "Epoch [3440], val_loss: 5238.8472\n",
            "Epoch [3460], val_loss: 5238.8086\n",
            "Epoch [3480], val_loss: 5238.6787\n",
            "Epoch [3500], val_loss: 5238.6396\n",
            "Epoch [3520], val_loss: 5238.4370\n",
            "Epoch [3540], val_loss: 5238.3955\n",
            "Epoch [3560], val_loss: 5238.3315\n",
            "Epoch [3580], val_loss: 5238.3818\n",
            "Epoch [3600], val_loss: 5238.2339\n",
            "Epoch [3620], val_loss: 5238.2109\n",
            "Epoch [3640], val_loss: 5238.1362\n",
            "Epoch [3660], val_loss: 5238.0503\n",
            "Epoch [3680], val_loss: 5238.0293\n",
            "Epoch [3700], val_loss: 5237.9854\n",
            "Epoch [3720], val_loss: 5237.8872\n",
            "Epoch [3740], val_loss: 5237.8296\n",
            "Epoch [3760], val_loss: 5237.6577\n",
            "Epoch [3780], val_loss: 5237.6743\n",
            "Epoch [3800], val_loss: 5237.5996\n",
            "Epoch [3820], val_loss: 5237.5220\n",
            "Epoch [3840], val_loss: 5237.4951\n",
            "Epoch [3860], val_loss: 5237.3809\n",
            "Epoch [3880], val_loss: 5237.2949\n",
            "Epoch [3900], val_loss: 5237.2817\n",
            "Epoch [3920], val_loss: 5237.1523\n",
            "Epoch [3940], val_loss: 5237.1445\n",
            "Epoch [3960], val_loss: 5237.0229\n",
            "Epoch [3980], val_loss: 5236.9023\n",
            "Epoch [4000], val_loss: 5236.9429\n",
            "Epoch [4020], val_loss: 5236.8496\n",
            "Epoch [4040], val_loss: 5236.7930\n",
            "Epoch [4060], val_loss: 5236.7246\n",
            "Epoch [4080], val_loss: 5236.7251\n",
            "Epoch [4100], val_loss: 5236.6260\n",
            "Epoch [4120], val_loss: 5236.5806\n",
            "Epoch [4140], val_loss: 5236.4009\n",
            "Epoch [4160], val_loss: 5236.4297\n",
            "Epoch [4180], val_loss: 5236.3315\n",
            "Epoch [4200], val_loss: 5236.1401\n",
            "Epoch [4220], val_loss: 5236.2490\n",
            "Epoch [4240], val_loss: 5236.0269\n",
            "Epoch [4260], val_loss: 5236.1025\n",
            "Epoch [4280], val_loss: 5235.9214\n",
            "Epoch [4300], val_loss: 5235.8350\n",
            "Epoch [4320], val_loss: 5235.8770\n",
            "Epoch [4340], val_loss: 5235.8838\n",
            "Epoch [4360], val_loss: 5235.7617\n",
            "Epoch [4380], val_loss: 5235.5996\n",
            "Epoch [4400], val_loss: 5235.5957\n",
            "Epoch [4420], val_loss: 5235.5249\n",
            "Epoch [4440], val_loss: 5235.4897\n",
            "Epoch [4460], val_loss: 5235.3330\n",
            "Epoch [4480], val_loss: 5235.3110\n",
            "Epoch [4500], val_loss: 5235.2998\n",
            "Epoch [4520], val_loss: 5235.1162\n",
            "Epoch [4540], val_loss: 5235.0430\n",
            "Epoch [4560], val_loss: 5235.0845\n",
            "Epoch [4580], val_loss: 5234.9834\n",
            "Epoch [4600], val_loss: 5234.9287\n",
            "Epoch [4620], val_loss: 5234.8950\n",
            "Epoch [4640], val_loss: 5234.9053\n",
            "Epoch [4660], val_loss: 5234.7329\n",
            "Epoch [4680], val_loss: 5234.6802\n",
            "Epoch [4700], val_loss: 5234.6348\n",
            "Epoch [4720], val_loss: 5234.5757\n",
            "Epoch [4740], val_loss: 5234.3667\n",
            "Epoch [4760], val_loss: 5234.4028\n",
            "Epoch [4780], val_loss: 5234.2837\n",
            "Epoch [4800], val_loss: 5234.2402\n",
            "Epoch [4820], val_loss: 5234.1567\n",
            "Epoch [4840], val_loss: 5234.0249\n",
            "Epoch [4860], val_loss: 5233.9697\n",
            "Epoch [4880], val_loss: 5233.9585\n",
            "Epoch [4900], val_loss: 5233.9087\n",
            "Epoch [4920], val_loss: 5233.8984\n",
            "Epoch [4940], val_loss: 5233.7993\n",
            "Epoch [4960], val_loss: 5233.6758\n",
            "Epoch [4980], val_loss: 5233.6318\n",
            "Epoch [5000], val_loss: 5233.5122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbnK1dInzAma"
      },
      "source": [
        "**Q: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ06g0qVzAmb"
      },
      "source": [
        "val_loss = 5233.5122"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGNNgu47zAmd"
      },
      "source": [
        "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH4767wkzAmd"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjdccZDbzAmd"
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)        # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTVcpGTBzAme",
        "outputId": "3d82dc83-f0a6-464d-a086-d218d41369cd"
      },
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([32.0000,  1.0000, 32.8054,  1.0000,  0.0000,  1.0000])\n",
            "Target: tensor([5310.6392])\n",
            "Prediction: tensor([6188.1406])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz_kAm84zAme",
        "outputId": "05fe7a8c-5e3d-4864-b3fb-f1b942df3331"
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([24.0000,  1.0000, 38.9455,  0.0000,  1.0000,  2.0000])\n",
            "Target: tensor([45370.2344])\n",
            "Prediction: tensor([7444.4590])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOEe72RQzAme",
        "outputId": "9a0857a5-aa70-4f2a-e360-a062fca462f9"
      },
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([64.0000,  0.0000, 29.2115,  3.0000,  0.0000,  1.0000])\n",
            "Target: tensor([19582.2930])\n",
            "Prediction: tensor([17705.7227])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Q0QdfozAmf"
      },
      "source": [
        "Are you happy with your model's predictions? Try to improve them further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py8Aq6TAzAmg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}